{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:04.011242Z",
     "start_time": "2019-06-17T06:02:03.037009Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import ast\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:46.623373Z",
     "start_time": "2019-06-17T06:02:43.696845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['story_id', 'question', 'answer_char_ranges', 'is_answer_absent',\n",
      "       'is_question_bad', 'validated_answers', 'story_text'],\n",
      "      dtype='object')\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_char_ranges</th>\n",
       "      <th>is_answer_absent</th>\n",
       "      <th>is_question_bad</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>294:297|None|None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./cnn/stories/c48228a52f26aca65c31fad273e66164...</td>\n",
       "      <td>Where was one employee killed?</td>\n",
       "      <td>34:60|1610:1618|34:60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CNN) -- Fighting in the volatile Sudanese reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...</td>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>103:127|114:127|839:853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./cnn/stories/0cf66b646e9b32076513c050edf32a79...</td>\n",
       "      <td>How many years old was the businessman?</td>\n",
       "      <td>538:550|538:550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CNN)  -- England international footballer Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./cnn/stories/13012604e3203c18df09289dfedd14cd...</td>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>690:742|688:791|630:646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            story_id  \\\n",
       "0  ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...   \n",
       "1  ./cnn/stories/c48228a52f26aca65c31fad273e66164...   \n",
       "2  ./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...   \n",
       "3  ./cnn/stories/0cf66b646e9b32076513c050edf32a79...   \n",
       "4  ./cnn/stories/13012604e3203c18df09289dfedd14cd...   \n",
       "\n",
       "                                            question       answer_char_ranges  \\\n",
       "0          What was the amount of children murdered?        294:297|None|None   \n",
       "1                     Where was one employee killed?    34:60|1610:1618|34:60   \n",
       "2  who did say South Africa did not issue a visa ...  103:127|114:127|839:853   \n",
       "3            How many years old was the businessman?          538:550|538:550   \n",
       "4                      What frightened the families?  690:742|688:791|630:646   \n",
       "\n",
       "   is_answer_absent is_question_bad             validated_answers  \\\n",
       "0               0.0             0.0     {\"none\": 1, \"294:297\": 2}   \n",
       "1               0.0             0.0                           NaN   \n",
       "2               0.0             0.0  {\"839:853\": 1, \"103:127\": 2}   \n",
       "3               0.0             0.0                           NaN   \n",
       "4               0.0             0.0  {\"688:791\": 2, \"690:742\": 1}   \n",
       "\n",
       "                                          story_text  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...  \n",
       "1  (CNN) -- Fighting in the volatile Sudanese reg...  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...  \n",
       "3  (CNN)  -- England international footballer Ste...  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('combined-newsqa-data-v1.csv')\n",
    "print(data.columns)\n",
    "print(type(data['is_question_bad'][0]))\n",
    "\n",
    "# remove Q/A pairs that are invalid or missing\n",
    "#data = data[(data.is_question_bad=='0.0') & (data.is_answer_absent=='0.0')]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:49.040788Z",
     "start_time": "2019-06-17T06:02:49.033284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(data['is_question_bad'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:50.283808Z",
     "start_time": "2019-06-17T06:02:49.804811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119633\n",
      "12088\n"
     ]
    }
   ],
   "source": [
    "# 119,633 Q/A's , 12088 articles\n",
    "print(len(data))\n",
    "print(len(data['story_text'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:50.711182Z",
     "start_time": "2019-06-17T06:02:50.702625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc = data['story_text'][0]\n",
    "first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:52.916660Z",
     "start_time": "2019-06-17T06:02:52.908513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc[294:297]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:53.482038Z",
     "start_time": "2019-06-17T06:02:53.473105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johannesburg (CNN) -- Miffed by a visa delay that led the Dalai Lama to cancel a trip to South Africa, Archbishop Desmond Tutu lashed out at his government Tuesday, saying it had acted worse than apartheid regimes and had forgotten all that the nation stood for.\\n\\n\\n\\n\\n\\n\"When we used to apply for passports under the apartheid government, we never knew until the last moment what their decision was,\" Tutu said at a news conference. \"Our government is worse than the apartheid government because at least you were expecting it from the apartheid government.\\n\\n\\n\\n\\n\\n\"I have to say that I can\\'t believe this. I really can\\'t believe this,\" Tutu said. \"You have to wake me up and tell me this is actually happening here.\"\\n\\n\\n\\n\\n\\nThe Dalai Lama scrapped his planned trip to South Africa this week after the nation failed to issue him a visa in time, his spokesman said.\\n\\n\\n\\n\\n\\nVisa applications for him and his entourage were submitted to the South African High Commission in New Delhi, India, at the end of August, and original passports were submitted on September 20, more than two weeks ago, a statement on his website said.\\n\\n\\n\\n\\n\\nHowever, South Africa\\'s foreign affairs office said it did not refuse a visa.\\n\\n\\n\\n\\n\\n\"South Africa will not comment on the decision, because it is not our decision, it is his decision,\" according to spokesman Clayson Monyela, who said the visa application was still under consideration.\\n\\n\\n\\n\\n\\nThe Dalai Lama had been invited to the country to receive the Mahatma Gandhi International Award for Peace and Reconciliation and to speak at a number of events, including a lecture in honor of Tutu\\'s 80th birthday. Tutu and the Dalai Lama are recipients of the Nobel Peace Prize.\\n\\n\\n\\n\\n\\nTutu said he would pray for the defeat of South Africa\\'s government, led by the African National Congress (ANC), which is rooted in the fight against the system of apartheid, or legal racial separation, that was present in South Africa until 1994.\\n\\n\\n\\n\\n\\n\"You are disgraceful,\" Tutu said about the government. \"You are behaving in a way that is totally at variance with the things for which we stood.\"\\n\\n\\n\\n\\n\\nThe ANC plans to call on government officials to explain to South Africans why the visa process was delayed, spokesman Jackson Mtembu said. He said everyone was in the dark about this matter.\\n\\n\\n\\n\\n\\nBut he also suggested that Tutu calm down. A comparison to apartheid regimes, he said, was unfair.\\n\\n\\n\\n\\n\\nThis is not the first time the Dalai Lama has not been able to visit South Africa. In 2009, South Africa refused the Tibetan spiritual leader a visa to attend an international peace conference, saying it was not in the country\\'s interest for him to attend.\\n\\n\\n\\n\\n\\nIn refusing the 2009 application, South Africa said that if the Dalai Lama attended the conference, the focus would shift away from the 2010 World Cup, the global soccer championship it was hosting.\\n\\n\\n\\n\\n\\n\"We cannot allow focus to shift to China and Tibet,\" presidential spokesman Thabo Masebe said, adding that South Africa had gained much from its trading relationship with China.\\n\\n\\n\\n\\n\\nThe Dalai Lama fled Tibet in 1959 after a failed uprising against Chinese rule, and China pressures governments around the world to deny him any legitimacy.\\n\\n\\n\\n\\n\\nSpeculation surfaced Tuesday that this year\\'s visit was also affected by South Africa\\'s relationship with China.\\n\\n\\n\\n\\n\\nSouth African Vice President Kgalema Motlanthe visited Beijing last week and met with Chinese President Hu Jintao to discuss bolstering bilateral ties.\\n\\n\\n\\n\\n\\nMotlanthe said South Africa was ready to boost the strategic partnership between the two countries to a new stage, according to the official Chinese news agency Xinhua.\\n\\n\\n\\n\\n\\nBut Monyela said the application had nothing to do with China.\\n\\n\\n\\n\\n\\n\"We are a sovereign nation which takes decisions in our domestic interest,\" Monyela said.\\n\\n\\n\\n\\n\\nThe Dalai Lama posted a message on Twitter last week that said: \"Even if the Chinese leave nothing but ashes, Tibet will rise from these ashes as a free country even if it takes a long time to do so.\"\\n\\n\\n\\n\\n\\nKim Norgaard, CNN\\'s Johannesburg bureau chief, contributed to this report.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_doc = data['story_text'][2]\n",
    "second_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:55.298362Z",
     "start_time": "2019-06-17T06:02:55.292857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archbishop Desmond Tutu \n",
      "Desmond Tutu \n",
      "his spokesman \n"
     ]
    }
   ],
   "source": [
    "print(second_doc[103:127])\n",
    "print(second_doc[114:127])\n",
    "print(second_doc[839:853])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers given by different human reviewers are in the answer_char_ranges column and the validated_answers column. These values are string index ranges within the document that represent the answer. For each row, we need to determine which character range is the best answer to use and extract it. There are a couple ways we could approach this problem, the first is to have a model that takes the question(str), the story(str), spits out an answer(str).\n",
    "\n",
    "or we could have it spit back out the string indexes themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:57.405886Z",
     "start_time": "2019-06-17T06:02:57.370169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>{\"301:324\": 2}</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>{\"63:97\": 2}</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "              validated_answers  \\\n",
       "0     {\"none\": 1, \"294:297\": 2}   \n",
       "2  {\"839:853\": 1, \"103:127\": 2}   \n",
       "4  {\"688:791\": 2, \"690:742\": 1}   \n",
       "6                {\"301:324\": 2}   \n",
       "8                  {\"63:97\": 2}   \n",
       "\n",
       "                                          story_text  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...  \n",
       "6  CNN affiliates report on where job seekers are...  \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove uneeded columns\n",
    "df = data[['question','validated_answers','story_text']]\n",
    "df = df.dropna()\n",
    "df = df.iloc[0:10000] # reduce size for development purposes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:59.537193Z",
     "start_time": "2019-06-17T06:02:59.527978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "      <td>688.0</td>\n",
       "      <td>791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>{\"301:324\": 2}</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "      <td>301.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>{\"63:97\": 2}</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "              validated_answers  \\\n",
       "0     {\"none\": 1, \"294:297\": 2}   \n",
       "2  {\"839:853\": 1, \"103:127\": 2}   \n",
       "4  {\"688:791\": 2, \"690:742\": 1}   \n",
       "6                {\"301:324\": 2}   \n",
       "8                  {\"63:97\": 2}   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...        294.0      297.0  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...        103.0      127.0  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...        688.0      791.0  \n",
       "6  CNN affiliates report on where job seekers are...        301.0      324.0  \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...         63.0       97.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loops through the rows and prints the question along with the first answer given\n",
    "start_truth = []\n",
    "end_truth = []\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        answers = ast.literal_eval(row['validated_answers'])\n",
    "        sorted_ans = sorted(answers.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        #print(sorted_ans)\n",
    "        start, end = sorted_ans[0][0].split(':')\n",
    "        start_truth.append(int(start))\n",
    "        end_truth.append(int(end))\n",
    "    except ValueError:\n",
    "        start_truth.append(np.nan)\n",
    "        end_truth.append(np.nan)\n",
    "        pass\n",
    "df['start_truth'] = start_truth\n",
    "df['end_truth'] = end_truth\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "      <td>688.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "      <td>301.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \\\n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...        294.0      297.0   \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...        103.0      127.0   \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...        688.0      791.0   \n",
       "6  CNN affiliates report on where job seekers are...        301.0      324.0   \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...         63.0       97.0   \n",
       "\n",
       "    ss  \n",
       "0  0.0  \n",
       "2  0.0  \n",
       "4  0.0  \n",
       "6  0.0  \n",
       "8  0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df.drop(columns=['validated_answers'])\n",
    "final['ss'] = np.zeros(len(final))\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char-level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('”', '!', 'ţ', ']', 'ã')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = ''\n",
    "m = 0\n",
    "len_nums = []\n",
    "for col in ['question','story_text']:\n",
    "    for text in final[col]:\n",
    "        m = max(m, len(text))\n",
    "        full_text += text.lower()\n",
    "    len_nums.append(m)\n",
    "    m=0\n",
    "    \n",
    "# get the set of all characters\n",
    "characters = tuple(set(full_text))\n",
    "characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'”': 0, '!': 1, 'ţ': 2, ']': 3, 'ã': 4, ';': 5, '¨': 6, 'º': 7, 'ø': 8, ' ': 9, 'v': 10, '(': 11, 'z': 12, '‚': 13, 'ü': 14, '_': 15, 'x': 16, 'ç': 17, ')': 18, 't': 19, ',': 20, 'd': 21, 'g': 22, '\\u202a': 23, 'j': 24, '`': 25, '-': 26, 'ó': 27, 'm': 28, 'ô': 29, 'r': 30, 'ê': 31, '©': 32, '¾': 33, 'f': 34, '•': 35, 'î': 36, 'ñ': 37, 'â': 38, 'l': 39, 'i': 40, 'k': 41, 'c': 42, '5': 43, 'w': 44, 'ÿ': 45, 'e': 46, '$': 47, '#': 48, 'q': 49, '&': 50, '\"': 51, '±': 52, '2': 53, 'í': 54, '>': 55, \"'\": 56, 'ï': 57, 'ş': 58, 'ä': 59, 'o': 60, '9': 61, '0': 62, '=': 63, 'h': 64, '7': 65, '?': 66, '¯': 67, 'è': 68, '¢': 69, '£': 70, 'ë': 71, '¥': 72, '×': 73, '6': 74, '.': 75, '}': 76, ':': 77, '3': 78, 'á': 79, 'y': 80, 'ú': 81, '|': 82, 'ò': 83, '@': 84, '¬': 85, '³': 86, '´': 87, '\\\\': 88, 'à': 89, '½': 90, 'b': 91, '€': 92, 'ù': 93, 'ö': 94, 'n': 95, '·': 96, '°': 97, 'é': 98, '®': 99, '+': 100, '\\xad': 101, '»': 102, '¡': 103, 'p': 104, '8': 105, '[': 106, 'a': 107, 'þ': 108, '*': 109, '\\xa0': 110, '1': 111, '¹': 112, '§': 113, '/': 114, 's': 115, '\\u202c': 116, 'û': 117, '—': 118, 'u': 119, '\\n': 120, '4': 121, '%': 122}\n"
     ]
    }
   ],
   "source": [
    "# use enumeration to give the characters integer values\n",
    "int2char = dict(enumerate(characters))\n",
    "\n",
    "# create the look up dictionary from characters to the assigned integers\n",
    "char2int = {char: index for index, char in int2char.items()}\n",
    "print(char2int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 11349\n"
     ]
    }
   ],
   "source": [
    "q_max, story_max = len_nums\n",
    "print(q_max, story_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_s(seq):\n",
    "    for i, char in enumerate(seq):\n",
    "        if char == 0:\n",
    "            continue\n",
    "        else: return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>10114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>7243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>688.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>9077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>301.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>5733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>8539.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        294.0      297.0   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        103.0      127.0   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        688.0      791.0   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        301.0      324.0   \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         63.0       97.0   \n",
       "\n",
       "        ss  \n",
       "0  10114.0  \n",
       "2   7243.0  \n",
       "4   9077.0  \n",
       "6   5733.0  \n",
       "8   8539.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_start = False\n",
    "\n",
    "for i, row in final.iterrows():\n",
    "    for col, N in zip(['question','story_text'], [q_max, story_max]):\n",
    "        enc = np.zeros(N, dtype=np.int32)\n",
    "        \n",
    "        row[col] = np.array([char2int[char] for char in row[col].lower()])\n",
    "        l = min(N, len(row[col]))\n",
    "        \n",
    "        if padding_start:\n",
    "            enc[:l] = row[col][:l]\n",
    "        else:\n",
    "            enc[N-l:] = row[col][:l]\n",
    "        \n",
    "        final[col][i] = enc\n",
    "        final['ss'][i] = N-l\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 30 19 75]\n",
      "7243\n"
     ]
    }
   ],
   "source": [
    "print(final.iloc[1,1])\n",
    "print(find_s(final.iloc[1,1]))\n",
    "# find_s([0,0,0,0,0,0,1,2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final[['question', 'story_text', 'ss']], \n",
    "                                                    final[['start_truth','end_truth']], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 2620,  2165,  5896, 11169,  4408,  7251, 13871, 15569,  4459,\n",
      "            16101,\n",
      "            ...\n",
      "             4609, 15400, 12242,  1326, 17310, 15819, 14346, 14897,  2295,\n",
      "            20192],\n",
      "           dtype='int64', length=5822)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "      <th>ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>6931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>8949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11169</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9033.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "2620   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2165   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5896   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11169  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4408   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              story_text      ss  \n",
       "2620   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6931.0  \n",
       "2165   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  9698.0  \n",
       "5896   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  8949.0  \n",
       "11169  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  9016.0  \n",
       "4408   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  9033.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_train.end_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>172.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>339.0</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>171.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11169</th>\n",
       "      <td>120.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>171.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_truth  end_truth\n",
       "2620         172.0      194.0\n",
       "2165         339.0      357.0\n",
       "5896         171.0      176.0\n",
       "11169        120.0      130.0\n",
       "4408         171.0      184.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsQADataset(Dataset):\n",
    "    def __init__(self, X, y, N=400, padding_start=False):\n",
    "        self.start = y['start_truth'].values\n",
    "        self.end = y['end_truth'].values\n",
    "        self.question = X['question'].values\n",
    "        self.story_text = X['story_text'].values\n",
    "        self.ss = X['ss'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.question)\n",
    "        #qs = np.array([find_s(seq) for seq in self.question])\n",
    "        # ss = np.array([find_s(seq) for seq in self.story_text])\n",
    "        return self.question[idx], self.story_text[idx], self.start[idx] + self.ss[idx], self.end[idx] + self.ss[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsQADataset(X_train, y_train)\n",
    "test_ds = NewsQADataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  44,  64,  60,   9,  39,  46,  34,  19,\n",
       "          9,  28,  46,  16,  40,  42,  60,  56, 115,   9,  22,  60,  10,\n",
       "         46,  30,  95,  28,  46,  95,  19,  66], dtype=int32),\n",
       " array([ 0,  0,  0, ..., 40, 21, 75], dtype=int32),\n",
       " 7103.0,\n",
       " 7125.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 112]) torch.Size([100, 11349]) torch.Size([100]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   0,   0,  ...,  34,  60,  30],\n",
       "         [  0,   0,   0,  ...,  64,  46,  28],\n",
       "         [  0,   0,   0,  ...,  30,  95,  66],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,  42, 115,  66],\n",
       "         [  0,   0,   0,  ...,  60,  39,  66],\n",
       "         [  0,   0,   0,  ...,  30,  80,  66]], dtype=torch.int32),\n",
       " tensor([[  0,   0,   0,  ...,  42, 107,  75],\n",
       "         [  0,   0,   0,  ...,  21,  75,  51],\n",
       "         [  0,   0,   0,  ...,  46,  95,  21],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,  46,  95,  21],\n",
       "         [  0,   0,   0,  ...,  30,  46,   1],\n",
       "         [  0,   0,   0,  ...,  30,  19,  75]], dtype=torch.int32),\n",
       " tensor([ 8794.,  7364.,  5671.,  7590.,  5701.,  8446.,  9932.,  8427., 10559.,\n",
       "          9561.,  8491.,  9619.,  3609.,  4880.,  9520.,  6172.,  6762., 10231.,\n",
       "          9180.,  6210.,  9126., 11162.,  9835.,  3379., 10008., 11236.,  6531.,\n",
       "          8321.,  6821., 10160.,  9475.,  9222., 10718.,  9344.,  8204., 10045.,\n",
       "         10592.,  6474., 10904.,  6630.,  8538., 11042.,  9534.,  7835.,  9954.,\n",
       "          7260.,  9900.,  8939.,  9245.,  7500., 10494., 10271.,  9402.,  7567.,\n",
       "         10084.,  7206.,  8918.,  9837.,  7303.,  9463.,  3127.,  5628., 10577.,\n",
       "          7520.,  9738.,  8978., 10507.,  8456., 10113., 10658., 10572.,  8114.,\n",
       "          5504., 10484., 10269.,  9100.,  8300.,  6221.,  6767.,  7463.,  8118.,\n",
       "          9602.,  9455.,  9458.,  9800., 10571.,  9455.,  9605.,  6481.,  8994.,\n",
       "          9005.,  7813.,  8138., 10382.,  9082., 10698.,  5849.,  7480.,  7923.,\n",
       "          8029.], dtype=torch.float64),\n",
       " tensor([ 8844.,  7388.,  5686.,  7611.,  5715.,  8461.,  9954.,  8444., 10581.,\n",
       "          9638.,  8605.,  9650.,  3620.,  4929.,  9577.,  6388.,  6836., 10245.,\n",
       "          9196.,  6520.,  9241., 11258.,  9841.,  3397., 10024., 11240.,  6564.,\n",
       "          8377.,  6865., 10208.,  9492.,  9259., 10827.,  9398.,  8234., 10065.,\n",
       "         10608.,  6485., 10931.,  6654.,  8548., 11094.,  9555.,  7855., 10065.,\n",
       "          7267.,  9923.,  9016.,  9267.,  7550., 10521., 10285.,  9417.,  7576.,\n",
       "         10119.,  7216.,  8925.,  9854.,  7321.,  9476.,  3207.,  5649., 10599.,\n",
       "          7549.,  9756.,  9016., 10526.,  8465., 10163., 10769., 10576.,  8141.,\n",
       "          5515., 10500., 10282.,  9153.,  8314.,  6237.,  6788.,  7522.,  8146.,\n",
       "          9652.,  9481.,  9470.,  9805., 10607.,  9476.,  9628.,  6489.,  9001.,\n",
       "          9019.,  8017.,  8180., 10395.,  9088., 10733.,  5865.,  7488.,  7967.,\n",
       "          8034.], dtype=torch.float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, s, start, end = next(iter(train_dl))\n",
    "print(q.shape, s.shape, start.shape, end.shape)\n",
    "q, s, start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, q_max, story_max):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear2 = nn.Linear(200, story_max)\n",
    "        self.linear_start = nn.Linear(story_max, story_max+1)\n",
    "        self.linear_end = nn.Linear(story_max, story_max+1)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x1 = self.embeddings(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        out_pack1, ht1= self.gru(x1)\n",
    "        \n",
    "        x2 = self.embeddings(x2)\n",
    "        x2 = self.dropout(x2)\n",
    "        out_pack2, ht2= self.gru(x2)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((ht1[-1], ht2[-1]),1)\n",
    "        \n",
    "        x = F.relu(self.linear2(x))\n",
    "        start = self.linear_start(x)\n",
    "        end = self.linear_end(x)\n",
    " \n",
    "        return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've taken the functions from her last name classification model because that uses character-level embeddings as well. I'm using a naive version that just concats the question with the story and uses that as input into the RNN. I used that with regressing 2 outputs (start, end) and I got it to train but not sure how well it's actually doing. I think we correct way to do this is to treat it as a classification problem where each index of the story is a categroy and we use those predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "def vectorize(labels, size=7361):\n",
    "    result = []\n",
    "    for s in labels:\n",
    "        #print(s)\n",
    "        row = np.zeros(size)\n",
    "        row[int(s)] = 1\n",
    "        result.append(row)\n",
    "        \n",
    "    return result\n",
    "\n",
    "vectorize([1, 10, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=5, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for q, s, start_, end_ in train_dl:\n",
    "            #start_vec = vectorize(start_)\n",
    "            #end_vec = vectorize(end_)\n",
    "            q = q.long()\n",
    "            s = s.long()\n",
    "            start_ = start_.long()\n",
    "            end_ = end_.long()\n",
    "\n",
    "            start, end = model(q, s)\n",
    "            loss_start = F.cross_entropy(start, start_)\n",
    "\n",
    "            loss_end = F.cross_entropy(end, end_)\n",
    "            loss = loss_start + loss_end\n",
    "            \n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*end_.shape[0]\n",
    "            total += end_.shape[0]\n",
    "        val_loss = val_metrics(model, test_dl)\n",
    "        #if i % 5 == 1:\n",
    "        print(\"train loss %.3f val loss %.3f and val accuracy NA.3f\" % (sum_loss/total, val_loss))\n",
    "            \n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for q, s, start_, end_ in valid_dl:\n",
    "        q = q.long()\n",
    "        s = s.long()\n",
    "        start_ = start_.long()\n",
    "        end_ = end_.long()\n",
    "\n",
    "        start, end = model(q, s)\n",
    "        #print(start, end)\n",
    "        #print(start.shape, end.shape)\n",
    "        \n",
    "        loss_start = F.cross_entropy(start, start_)\n",
    "        #print(loss_start)\n",
    "        \n",
    "        loss_end = F.cross_entropy(end, end_)\n",
    "        #print(loss_end)\n",
    "        \n",
    "        loss = loss_start + loss_end\n",
    "        #print(loss)\n",
    "        #\n",
    "        start_i = start.argmax(1)\n",
    "        end_i = end.argmax(1)\n",
    "        \n",
    "        \n",
    "        total += end_.shape[0]\n",
    "        sum_loss += loss.item()*end_.shape[0]\n",
    "    print(f'Predicted: {start_i}, Real: {start_}')\n",
    "    #print(f'Real: {start_}, {end_}')\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char2int)\n",
    "hidden_size = 100\n",
    "n_classes = 2\n",
    "emb_size = 10\n",
    "model = GRUModel(vocab_size, emb_size, hidden_size, q_max, story_max)\n",
    "\n",
    "# val_metrics(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tensor([10658, 10658, 10508, 10658, 10658, 10658, 10508, 10508, 10658, 10508,\n",
      "        10508, 10658, 10508, 10508, 10508, 10658, 10508,  8829, 10658, 10658,\n",
      "        10658, 10658, 10508, 10508, 10658, 10658, 10658, 10658, 10658, 10508,\n",
      "        10658, 10658, 10508, 10508, 10658, 10508, 10658, 10658, 10658,  7182,\n",
      "        10658,  8829, 10508, 10658, 10508,  8829, 10508, 10658, 10658, 10658,\n",
      "        10508, 10658,  8829, 10658, 10658, 10658, 10658, 10658, 10658, 10658,\n",
      "        10658, 10508, 10508, 10508, 10658, 10658, 10508, 10658, 10658, 10658,\n",
      "        10658, 10508,  9669, 10658, 10658,  8829, 10658, 10508, 10658, 10658,\n",
      "        10658, 10508, 10658, 10508, 10508, 10658, 10658, 10508, 10658, 10658,\n",
      "        10508, 10658, 10508, 10658, 10508, 10658]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 18.736 val loss 18.566 and val accuracy NA.3f\n",
      "Predicted: tensor([ 9022,  9022,  9022, 10135,  9022,  9022, 10135, 10135, 10135,  8933,\n",
      "         9022,  9022, 10135, 10135, 10135,  9022, 10135,  8933, 10135, 10135,\n",
      "         9022,  9022, 10135,  9022, 10135,  9022,  9022,  9022,  9022, 10135,\n",
      "         9022,  9022,  9022,  9022, 10135,  9022, 10135,  9022, 10135, 10135,\n",
      "         9022,  8933, 10135, 10135, 10135,  8933, 10135,  9022,  9022,  9022,\n",
      "         9022, 10135,  8933,  9022, 10135,  9022, 10135, 10135,  9022, 10135,\n",
      "         9022,  9022, 10135, 10135, 10135,  9022, 10135,  9022,  9022,  9022,\n",
      "        10135, 10135,  8933, 10135,  9022,  8933, 10135,  9022,  9022,  9022,\n",
      "        10135,  8933,  9022, 10135,  9022, 10135, 10135,  9022,  9022, 10135,\n",
      "         8933, 10135, 10135, 10135,  9022,  9022]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 17.962 val loss 21.180 and val accuracy NA.3f\n",
      "Predicted: tensor([ 9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734, 10123,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734, 10123,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,  9734,\n",
      "         9734,  9734,  9734,  9734,  9734,  9734]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 18.021 val loss 20.499 and val accuracy NA.3f\n",
      "Predicted: tensor([ 8983,  8983,  8983,  8983,  8983,  8983,  8983,  8983,  8983,  8450,\n",
      "         8983,  8983,  8983,  8983,  8983,  8855,  8983,  8450,  8983,  8983,\n",
      "         8983,  8983,  8983,  8983,  8983,  8983,  8983, 10084,  8983,  8983,\n",
      "         8983,  8983,  8983,  8983,  8983,  8983,  8855,  8983,  8983,  8855,\n",
      "         8983,  9483,  8983,  8983,  8855,  9483,  8983, 10084,  8983, 10165,\n",
      "         8983,  8983,  9483,  8983,  8983,  8983,  8983,  8983,  8983,  8983,\n",
      "         8983,  8983,  8983,  8983,  8983,  8983,  8983,  8983,  8983,  8983,\n",
      "         8983,  8983,  8983,  8983,  8983,  9840,  8983,  8983,  8983,  8983,\n",
      "         8983,  8450,  8983,  8983,  8983,  8983, 10165,  8983,  8983,  8983,\n",
      "         8983,  8983,  8983,  8983,  8983, 10165]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 17.048 val loss 18.321 and val accuracy NA.3f\n",
      "Predicted: tensor([ 9002,  9002, 10132,  9032,  9964,  9964,  9032,  9032,  9032,  7032,\n",
      "         9964,  9964, 10132,  9964,  9032,  9704,  9964,  7032,  9964,  9964,\n",
      "        10135,  9964,  9032,  9964,  9964,  9964,  9964,  9002,  9964,  9032,\n",
      "         9964,  9438,  9964,  9964,  9964,  8731,  9964, 10279,  9002,  9032,\n",
      "         9704,  7032,  9032,  9964,  9964,  7032,  9964,  9002,  9964,  9002,\n",
      "        10132,  9964,  7032, 10132,  9032,  9704,  9964, 10279,  8731, 10135,\n",
      "         9032,  9964, 10279,  8724, 10132,  9964,  8731,  9002,  9964,  9964,\n",
      "         9964,  9032,  7032,  9032, 10206,  7032,  9032,  8731,  9032,  9964,\n",
      "        10279,  7032,  9002,  9032, 10279,  9695,  9876,  8731,  9032,  9704,\n",
      "         7032,  9032,  9964,  9964,  9964,  8731]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 17.147 val loss 19.070 and val accuracy NA.3f\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(start_real, end_real, start_pred, end_pred):\n",
    "    # len(intersection) / len(union)\n",
    "    vals = []\n",
    "    for s1, e1, s2, e2 in zip(start_real, end_real, start_pred, end_pred):\n",
    "        real_range = set(range(s1, e1+1, 1))\n",
    "        pred_range = set(range(s2, e2+1, 1))\n",
    "        intersection = real_range.intersection(pred_range)\n",
    "        union = real_range.union(pred_range)\n",
    "        vals.append(len(intersection)/len(union))\n",
    "        \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.0001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for q, s, start_, end_ in train_dl:\n",
    "            #start_vec = vectorize(start_)\n",
    "            #end_vec = vectorize(end_)\n",
    "            q = q.long()\n",
    "            s = s.long()\n",
    "            start_ = start_.long()\n",
    "            end_ = end_.long()\n",
    "\n",
    "            start, end = model(q, s)\n",
    "            loss_start = F.cross_entropy(start, start_)\n",
    "\n",
    "            loss_end = F.cross_entropy(end, end_)\n",
    "            loss = loss_start + loss_end\n",
    "            \n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*end_.shape[0]\n",
    "            total += end_.shape[0]\n",
    "        val_loss, val_score = val_metrics(model, test_dl)\n",
    "        #if i % 5 == 1:\n",
    "        print(\"train loss %.3f val loss %.3f and val score %.3f\" % (sum_loss/total, val_loss, val_score))\n",
    "            \n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    scores = []\n",
    "    for q, s, start_, end_ in valid_dl:\n",
    "        q = q.long()\n",
    "        s = s.long()\n",
    "        start_ = start_.long()\n",
    "        end_ = end_.long()\n",
    "\n",
    "        start, end = model(q, s)\n",
    "        #print(start, end)\n",
    "        #print(start.shape, end.shape)\n",
    "        \n",
    "        loss_start = F.cross_entropy(start, start_)\n",
    "        #print(loss_start)\n",
    "        \n",
    "        loss_end = F.cross_entropy(end, end_)\n",
    "        #print(loss_end)\n",
    "        \n",
    "        loss = loss_start + loss_end\n",
    "        #print(loss)\n",
    "        #\n",
    "        start_i = start.argmax(1)\n",
    "        end_i = end.argmax(1)\n",
    "        #for st, en in zip(start_i, end_i):\n",
    "        \n",
    "        score = custom_metric(start_, end_, start_i, end_i)\n",
    "        scores.append(score)\n",
    "        \n",
    "        \n",
    "        total += end_.shape[0]\n",
    "        sum_loss += loss.item()*end_.shape[0]\n",
    "    \n",
    "    print(f'Predicted: {start_i}, Real: {start_}')\n",
    "    #print(f'Real: {start_}, {end_}')\n",
    "    return sum_loss/total, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char2int)\n",
    "hidden_size = 100\n",
    "n_classes = 2\n",
    "emb_size = 10\n",
    "model2 = GRUModel(vocab_size, emb_size, hidden_size, q_max, story_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tensor([10086,  8790,  8790,  8756, 10086,  8790, 10086, 10086,  8790, 10086,\n",
      "         8790,  8790,  8756,  8790,  8790, 10086, 10086,  9734, 10086, 10086,\n",
      "         8790, 10086, 10086, 10086,  8756, 10086, 10086, 10086, 10086, 10086,\n",
      "        10086, 10086,  8790,  8790,  8756, 10086, 10086, 10086, 10086,  8867,\n",
      "         8790, 10086, 10086, 10086, 10086,  9528, 10086, 10086, 10086, 10086,\n",
      "        10086,  8790, 10086, 10086,  8790,  8790,  8756,  8756, 10086,  8756,\n",
      "         8790, 10086,  8790, 10086,  8756, 10086, 10086, 10086,  8790, 10086,\n",
      "        10086, 10086,  8756, 10086, 10086,  8756, 10086, 10086, 10086, 10086,\n",
      "         8790,  8457, 10086, 10086, 10086, 10086,  8756, 10086,  8790, 10086,\n",
      "         9528, 10086, 10086,  8790, 10086,  8790]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 18.652 val loss 18.395 and val score 0.002\n",
      "Predicted: tensor([10135, 10494, 10494, 10494, 10494, 10494, 10494, 10494, 10494,  9168,\n",
      "        10135, 10494, 10494, 10494, 10494, 10494, 10494,  9688, 10494, 10494,\n",
      "        10135, 10135, 10494, 10494,  9786, 10494, 10135,  9855, 10494, 10494,\n",
      "        10494, 10494, 10494, 10494,  7999, 10494, 10494, 10494, 10494,  9855,\n",
      "        10494,  9528, 10494,  8446,  9855,  9528, 10135, 10135, 10123, 10494,\n",
      "        10494, 10494, 10841, 10135, 10494, 10494,  8815, 10494, 10494,  9787,\n",
      "        10494,  9855, 10494, 10494,  8815, 10135, 10135, 10135, 10494, 10494,\n",
      "         9855, 10494,  8815, 10494, 10494,  8815, 10494,  9282, 10494, 10494,\n",
      "        10494,  8815, 10135, 10494, 10123, 10135, 10135, 10123, 10123,  8446,\n",
      "         9528, 10494, 10135, 10494, 10135, 10494]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 16.711 val loss 20.560 and val score 0.004\n",
      "Predicted: tensor([ 7712,  9239,  9812,  9575,  8758,  6200,  9253,  9253,  9239,  7007,\n",
      "         9195,  8776,  9575,  9812,  9239,  9094,  9964,  6824,  9934, 10185,\n",
      "         9812,  9934,  9253,  9964,  9575,  9934,  9195,  9964,  9094,  9253,\n",
      "         8776,  9934,  9239,  8962,  6994,  7251,  9116,  8776,  9964,  7454,\n",
      "        10294,  7462,  9253,  6245, 10878,  9150, 10503,  9812,  5909,  9173,\n",
      "         9094,  9812,  7360,  9964,  9964, 10294,  8418,  9575,  8962,  6245,\n",
      "        10031,  5909,  9812,  9812,  8418,  9195, 10503,  9195, 10415,  9063,\n",
      "         8962,  9253,  7640,  7251,  9812, 10828,  9964,  8776,  9094,  8758,\n",
      "         9239,  7462,  9934, 10522,  7712, 10185,  9264,  5909,  9144,  6245,\n",
      "         8792,  8776,  9173,  8851,  9173,  9812]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 15.789 val loss 19.951 and val score 0.004\n",
      "Predicted: tensor([10252,  9725,  8947,  8018,  8776,  8190,  8555,  7365,  9725,  5909,\n",
      "         4680,  8776,  9681,  6590,  9725,  9094,  9330,  5937,  9934,  7947,\n",
      "         8776,  9934,  7365,  7475,  6001,  8776, 10818,  7475,  9094,  7365,\n",
      "         4725,  8776,  7850,  9456,  6400, 10507,  6728,  8776,  7850,  7539,\n",
      "        10333,  9481,  7365,  7947,  6038,  7679,  6038,  9038,  5909,  9313,\n",
      "         9094,  9725,  9481,  7475,  9572, 10315,  7947,  9681, 10582,  8846,\n",
      "         9818,  6768,  8776,  9725,  7627,  9934, 10269,  9660, 10759,  9063,\n",
      "         9117, 10452,  9641,  8406,  9725, 10828,  9456,  8687,  9094,  8776,\n",
      "         9725,  9492,  9934,  7710, 10818,  6001,  7947,  5909, 10334,  7947,\n",
      "         6951,  8776, 10308,  8851, 10818,  8851]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 14.743 val loss 22.862 and val score 0.004\n",
      "Predicted: tensor([ 8948,  9282,  9532,  6036,  9787, 10673,  8002,  7972,  7103,  3056,\n",
      "         8948,  9989, 11116,  9397,  9885,  9424,  9317,  9231,  9934,  5631,\n",
      "         8790,  8948,  7972, 10086,  5940,  9532,  9509, 10714, 10706, 11005,\n",
      "         9663,  9532,  9885, 10165,  5940,  6397,  5737,  9989,  7103,  8115,\n",
      "        10333,  8112,  7972,  9447, 10914,  8933, 10043,  8948,  7062, 10086,\n",
      "         9807,  9876, 10971, 10714,  7103, 10165,  5631,  6016, 11035,  6246,\n",
      "         9818,  8678,  8790,  9876,  8815,  8948,  5471,  9499, 11042, 10086,\n",
      "         9864,  7972,  9969,  9119,  9663, 10248,  9271,  9055,  9424,  8309,\n",
      "         9885,  6367,  9532,  8832,  8948,  6533,  8235,  8678,  9397,  5631,\n",
      "         8112,  9867,  8790,  6555,  9499,  8254]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 13.994 val loss 24.063 and val score 0.004\n",
      "Predicted: tensor([ 8790,  6607,  8525,  8939,  6904,  6898,  8850,  4314,  9964,  5600,\n",
      "         6975, 11214,  8939,  8829,  5708,  6904,  9059,  6824,  6975,  6089,\n",
      "        10135,  6975,  4314,  7434,  8939,  6975,  7744,  8752,  9677,  9414,\n",
      "         4725,  9353,  4282,  7936,  9357,  8118,  5737,  8218,  6607,  7454,\n",
      "         9087,  8838,  8712,  7753,  7542, 11324, 10125,  7558,  7794,  5751,\n",
      "         6898,  9675,  8610, 10135,  9964,  9087,  7196,  8939,  7936,  7762,\n",
      "         9662,  7794, 10123,  9155,  8363,  8468,  6991,  7062, 10792,  8582,\n",
      "         7050,  4314,  9969,  6265,  9200,  5352,  8124,  9282,  6904,  5156,\n",
      "         9287,  7085,  6975,  9327,  7653,  6089, 10152,  7794,  8829,  6089,\n",
      "         8112,  5708, 10135, 10444,  7794,  3647]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 13.221 val loss 23.707 and val score 0.004\n",
      "Predicted: tensor([ 7712,  8588,  8525,  9575,  4761,  8296,  8217,  8217,  9566,  3056,\n",
      "        10876,  6426,  5910,  7606,  6988,  6610, 10649,  6956,  4730,  8825,\n",
      "        10245,  9934,  8217,  7434,  8966,  7994,  8245, 11098,  9777,  7257,\n",
      "         4725,  7994,  4282,  8099,  9357,  9013,  5737,  8218,  6264,  7454,\n",
      "         5164,  8438,  8217,  9888,  8669, 10682,  7695,  5311,  8193,  8323,\n",
      "        11172,  7922,  7922,  7475, 11188,  5164,  7047,  9575,  8005,  8966,\n",
      "         9662,  8010,  7487,  8107,  9276,  9934,  8536,  8245,  7928,  9029,\n",
      "        10078,  8217,  7438,  9765,  7447, 10248,  8124,  9740, 11186,  7348,\n",
      "         6207,  6172,  6295,  7710,  5781,  9152, 10152,  6640,  9843,  7216,\n",
      "         8438,  8120,  5667,  7189,  8245,  8546]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 12.573 val loss 30.031 and val score 0.004\n",
      "Predicted: tensor([ 8790,  6049,  8508, 10657,  9639,  7215,  9334,  9697, 10063,  8866,\n",
      "        10876,  7669, 10544,  6590, 10063,  6674, 11264, 11325,  9934, 10810,\n",
      "         8747,  9968,  7517, 10600,  6170,  8909,  9660,  7519, 10660,  9736,\n",
      "         4725,  7488, 11224,  7507, 10484, 10040,  5737,  7958,  6557,  8115,\n",
      "         2482,  9481, 10072,  9401,  8669,  9433,  9482,  7578,  7062, 10554,\n",
      "         9837,  8354, 10809,  7924,  9572, 10294,  5348, 10956, 11033,  6779,\n",
      "         9379,  9600,  8876,  8074,  7983,  9968,  6350,  9552,  7538,  8867,\n",
      "         7519,  9697,  9969, 11066,  7447, 10828,  9639,  9102,  6674,  8093,\n",
      "         6780,  7085,  8866,  7710,  8733,  6850,  7043,  7519,  9950,  7216,\n",
      "         8112,  8983,  7924, 10294,  7519,  6565]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 11.738 val loss 26.492 and val score 0.003\n",
      "Predicted: tensor([ 8790,  6049,  8819,  9681, 10320,  8877,  9604,  7867,  4831,  3056,\n",
      "         8468,  5376,  9681,  6752,  9632,  6610, 11264, 11325,  9934,  8825,\n",
      "         8747,  9934,  7867,  7434,  7719, 10643, 10990,  9702, 11151,  9000,\n",
      "         4725,  9934, 10291, 10432, 11053, 10394,  5737,  8218,  6049, 11264,\n",
      "        10333,  8838,  9000,  8164, 10177, 10682, 10043,  7712,  5436,  5751,\n",
      "        10661,  6025,  8838,  9435,  9572, 11080,  5348,  9681,  7936,  6576,\n",
      "         7884,  9600,  7265,  9632,  7991,  9934,  6116, 10917,  7997,  5751,\n",
      "         9600,  9011,  8951,  9593,  7447, 10828,  3417,  9113, 11186, 10320,\n",
      "         8284,  7462,  6381, 10251, 10572,  6001,  9985,  2962,  9305,  8013,\n",
      "         8112,  9410,  5081,  6555, 10037,  9961]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 11.235 val loss 31.700 and val score 0.004\n",
      "Predicted: tensor([11042,  9248,  7835,  8818,  5093,  7480,  7646, 10230,  9964,  3056,\n",
      "        10428,  9989,  6022,  6590,  7949,  6610,  9330,  6824, 10576,  7989,\n",
      "         7012,  8948,  9302,  7434,  7719,  8071,  9765,  8530, 10660, 10421,\n",
      "         4725, 10557,  4459,  7507,  5940,  7324,  5737,  8218, 10211,  8115,\n",
      "        10333,  9824,  7646, 10244,  7542, 11324,  9910, 10079,  7232, 10554,\n",
      "         9999, 10213,  8838,  7317, 10935, 11080,  9180,  8939,  9271,  9955,\n",
      "        10466,  6857,  7265,  8671,  8815,  8948,  8136,  7232,  8084, 10554,\n",
      "        10271,  7646,  8951,  9593,  7447, 10828, 11163,  8270, 11186,  7481,\n",
      "         8457,  5511,  6463,  7847,  8402,  9463,  7316,  7358, 10334,  7313,\n",
      "         8452,  6847,  5895, 10294,  9454,  3647]), Real: tensor([11291,  9028, 10073,  9535, 10972,  9580,  7871,  9072,  9756,  8948,\n",
      "         9542,  9075,  9727, 10498,  8772,  8125,  8138,  9561, 10093,  8738,\n",
      "         7210,  8869,  9947, 10124,  7153, 10803,  5007,  6941,  9800,  8092,\n",
      "         8538,  9913, 10975,  5731,  4791, 11311,  9044,  8201,  6553, 10611,\n",
      "         9618, 10298,  9036, 10226,  7453,  9435,  8870,  9559,  7339,  8650,\n",
      "        10629,  8095,  9380,  7672,  9576,  7926,  8464,  9976,  8449, 10313,\n",
      "        10647,  4400, 10550,  6262,  5837,  5578,  7626,  5257,  5564,  9404,\n",
      "         5277,  6684, 10477,  9340, 10378,  6597,  9244,  7159,  7732, 10438,\n",
      "         9647,  9747,  9659, 10194,  7126,  7053,  7063,  6013, 10268,  8341,\n",
      "         8991, 10281,  4811,  8622,  7308,  7375])\n",
      "train loss 10.495 val loss 36.328 and val score 0.004\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
