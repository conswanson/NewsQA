{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:04.011242Z",
     "start_time": "2019-06-17T06:02:03.037009Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import ast\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:46.623373Z",
     "start_time": "2019-06-17T06:02:43.696845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['story_id', 'question', 'answer_char_ranges', 'is_answer_absent',\n",
      "       'is_question_bad', 'validated_answers', 'story_text'],\n",
      "      dtype='object')\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_char_ranges</th>\n",
       "      <th>is_answer_absent</th>\n",
       "      <th>is_question_bad</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>294:297|None|None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./cnn/stories/c48228a52f26aca65c31fad273e66164...</td>\n",
       "      <td>Where was one employee killed?</td>\n",
       "      <td>34:60|1610:1618|34:60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CNN) -- Fighting in the volatile Sudanese reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...</td>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>103:127|114:127|839:853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./cnn/stories/0cf66b646e9b32076513c050edf32a79...</td>\n",
       "      <td>How many years old was the businessman?</td>\n",
       "      <td>538:550|538:550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CNN)  -- England international footballer Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./cnn/stories/13012604e3203c18df09289dfedd14cd...</td>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>690:742|688:791|630:646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            story_id  \\\n",
       "0  ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...   \n",
       "1  ./cnn/stories/c48228a52f26aca65c31fad273e66164...   \n",
       "2  ./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...   \n",
       "3  ./cnn/stories/0cf66b646e9b32076513c050edf32a79...   \n",
       "4  ./cnn/stories/13012604e3203c18df09289dfedd14cd...   \n",
       "\n",
       "                                            question       answer_char_ranges  \\\n",
       "0          What was the amount of children murdered?        294:297|None|None   \n",
       "1                     Where was one employee killed?    34:60|1610:1618|34:60   \n",
       "2  who did say South Africa did not issue a visa ...  103:127|114:127|839:853   \n",
       "3            How many years old was the businessman?          538:550|538:550   \n",
       "4                      What frightened the families?  690:742|688:791|630:646   \n",
       "\n",
       "   is_answer_absent is_question_bad             validated_answers  \\\n",
       "0               0.0             0.0     {\"none\": 1, \"294:297\": 2}   \n",
       "1               0.0             0.0                           NaN   \n",
       "2               0.0             0.0  {\"839:853\": 1, \"103:127\": 2}   \n",
       "3               0.0             0.0                           NaN   \n",
       "4               0.0             0.0  {\"688:791\": 2, \"690:742\": 1}   \n",
       "\n",
       "                                          story_text  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...  \n",
       "1  (CNN) -- Fighting in the volatile Sudanese reg...  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...  \n",
       "3  (CNN)  -- England international footballer Ste...  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('combined-newsqa-data-v1.csv')\n",
    "print(data.columns)\n",
    "print(type(data['is_question_bad'][0]))\n",
    "\n",
    "# remove Q/A pairs that are invalid or missing\n",
    "#data = data[(data.is_question_bad=='0.0') & (data.is_answer_absent=='0.0')]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:49.040788Z",
     "start_time": "2019-06-17T06:02:49.033284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(data['is_question_bad'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:50.283808Z",
     "start_time": "2019-06-17T06:02:49.804811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119633\n",
      "12088\n"
     ]
    }
   ],
   "source": [
    "# 119,633 Q/A's , 12088 articles\n",
    "print(len(data))\n",
    "print(len(data['story_text'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:50.711182Z",
     "start_time": "2019-06-17T06:02:50.702625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc = data['story_text'][0]\n",
    "first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:52.916660Z",
     "start_time": "2019-06-17T06:02:52.908513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc[294:297]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:53.482038Z",
     "start_time": "2019-06-17T06:02:53.473105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johannesburg (CNN) -- Miffed by a visa delay that led the Dalai Lama to cancel a trip to South Africa, Archbishop Desmond Tutu lashed out at his government Tuesday, saying it had acted worse than apartheid regimes and had forgotten all that the nation stood for.\\n\\n\\n\\n\\n\\n\"When we used to apply for passports under the apartheid government, we never knew until the last moment what their decision was,\" Tutu said at a news conference. \"Our government is worse than the apartheid government because at least you were expecting it from the apartheid government.\\n\\n\\n\\n\\n\\n\"I have to say that I can\\'t believe this. I really can\\'t believe this,\" Tutu said. \"You have to wake me up and tell me this is actually happening here.\"\\n\\n\\n\\n\\n\\nThe Dalai Lama scrapped his planned trip to South Africa this week after the nation failed to issue him a visa in time, his spokesman said.\\n\\n\\n\\n\\n\\nVisa applications for him and his entourage were submitted to the South African High Commission in New Delhi, India, at the end of August, and original passports were submitted on September 20, more than two weeks ago, a statement on his website said.\\n\\n\\n\\n\\n\\nHowever, South Africa\\'s foreign affairs office said it did not refuse a visa.\\n\\n\\n\\n\\n\\n\"South Africa will not comment on the decision, because it is not our decision, it is his decision,\" according to spokesman Clayson Monyela, who said the visa application was still under consideration.\\n\\n\\n\\n\\n\\nThe Dalai Lama had been invited to the country to receive the Mahatma Gandhi International Award for Peace and Reconciliation and to speak at a number of events, including a lecture in honor of Tutu\\'s 80th birthday. Tutu and the Dalai Lama are recipients of the Nobel Peace Prize.\\n\\n\\n\\n\\n\\nTutu said he would pray for the defeat of South Africa\\'s government, led by the African National Congress (ANC), which is rooted in the fight against the system of apartheid, or legal racial separation, that was present in South Africa until 1994.\\n\\n\\n\\n\\n\\n\"You are disgraceful,\" Tutu said about the government. \"You are behaving in a way that is totally at variance with the things for which we stood.\"\\n\\n\\n\\n\\n\\nThe ANC plans to call on government officials to explain to South Africans why the visa process was delayed, spokesman Jackson Mtembu said. He said everyone was in the dark about this matter.\\n\\n\\n\\n\\n\\nBut he also suggested that Tutu calm down. A comparison to apartheid regimes, he said, was unfair.\\n\\n\\n\\n\\n\\nThis is not the first time the Dalai Lama has not been able to visit South Africa. In 2009, South Africa refused the Tibetan spiritual leader a visa to attend an international peace conference, saying it was not in the country\\'s interest for him to attend.\\n\\n\\n\\n\\n\\nIn refusing the 2009 application, South Africa said that if the Dalai Lama attended the conference, the focus would shift away from the 2010 World Cup, the global soccer championship it was hosting.\\n\\n\\n\\n\\n\\n\"We cannot allow focus to shift to China and Tibet,\" presidential spokesman Thabo Masebe said, adding that South Africa had gained much from its trading relationship with China.\\n\\n\\n\\n\\n\\nThe Dalai Lama fled Tibet in 1959 after a failed uprising against Chinese rule, and China pressures governments around the world to deny him any legitimacy.\\n\\n\\n\\n\\n\\nSpeculation surfaced Tuesday that this year\\'s visit was also affected by South Africa\\'s relationship with China.\\n\\n\\n\\n\\n\\nSouth African Vice President Kgalema Motlanthe visited Beijing last week and met with Chinese President Hu Jintao to discuss bolstering bilateral ties.\\n\\n\\n\\n\\n\\nMotlanthe said South Africa was ready to boost the strategic partnership between the two countries to a new stage, according to the official Chinese news agency Xinhua.\\n\\n\\n\\n\\n\\nBut Monyela said the application had nothing to do with China.\\n\\n\\n\\n\\n\\n\"We are a sovereign nation which takes decisions in our domestic interest,\" Monyela said.\\n\\n\\n\\n\\n\\nThe Dalai Lama posted a message on Twitter last week that said: \"Even if the Chinese leave nothing but ashes, Tibet will rise from these ashes as a free country even if it takes a long time to do so.\"\\n\\n\\n\\n\\n\\nKim Norgaard, CNN\\'s Johannesburg bureau chief, contributed to this report.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_doc = data['story_text'][2]\n",
    "second_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:55.298362Z",
     "start_time": "2019-06-17T06:02:55.292857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archbishop Desmond Tutu \n",
      "Desmond Tutu \n",
      "his spokesman \n"
     ]
    }
   ],
   "source": [
    "print(second_doc[103:127])\n",
    "print(second_doc[114:127])\n",
    "print(second_doc[839:853])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers given by different human reviewers are in the answer_char_ranges column and the validated_answers column. These values are string index ranges within the document that represent the answer. For each row, we need to determine which character range is the best answer to use and extract it. There are a couple ways we could approach this problem, the first is to have a model that takes the question(str), the story(str), spits out an answer(str).\n",
    "\n",
    "or we could have it spit back out the string indexes themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:57.405886Z",
     "start_time": "2019-06-17T06:02:57.370169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>{\"301:324\": 2}</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>{\"63:97\": 2}</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "              validated_answers  \\\n",
       "0     {\"none\": 1, \"294:297\": 2}   \n",
       "2  {\"839:853\": 1, \"103:127\": 2}   \n",
       "4  {\"688:791\": 2, \"690:742\": 1}   \n",
       "6                {\"301:324\": 2}   \n",
       "8                  {\"63:97\": 2}   \n",
       "\n",
       "                                          story_text  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...  \n",
       "6  CNN affiliates report on where job seekers are...  \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove uneeded columns\n",
    "df = data[['question','validated_answers','story_text']]\n",
    "df = df.dropna()\n",
    "df = df.iloc[0:100] # reduce size for development purposes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T06:02:59.537193Z",
     "start_time": "2019-06-17T06:02:59.527978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>294</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "      <td>103</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "      <td>688</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>{\"301:324\": 2}</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "      <td>301</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>{\"63:97\": 2}</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "              validated_answers  \\\n",
       "0     {\"none\": 1, \"294:297\": 2}   \n",
       "2  {\"839:853\": 1, \"103:127\": 2}   \n",
       "4  {\"688:791\": 2, \"690:742\": 1}   \n",
       "6                {\"301:324\": 2}   \n",
       "8                  {\"63:97\": 2}   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...          294        297  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...          103        127  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...          688        791  \n",
       "6  CNN affiliates report on where job seekers are...          301        324  \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...           63         97  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loops through the rows and prints the question along with the first answer given\n",
    "start_truth = []\n",
    "end_truth = []\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        answers = ast.literal_eval(row['validated_answers'])\n",
    "        sorted_ans = sorted(answers.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        #print(sorted_ans)\n",
    "        start, end = sorted_ans[0][0].split(':')\n",
    "        start_truth.append(int(start))\n",
    "        end_truth.append(int(end))\n",
    "    except ValueError:\n",
    "        start_truth.append(np.nan)\n",
    "        end_truth.append(np.nan)\n",
    "        pass\n",
    "df['start_truth'] = start_truth\n",
    "df['end_truth'] = end_truth\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>294</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>Johannesburg (CNN) -- Miffed by a visa delay t...</td>\n",
       "      <td>103</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What frightened the families?</td>\n",
       "      <td>BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...</td>\n",
       "      <td>688</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is hiring?</td>\n",
       "      <td>CNN affiliates report on where job seekers are...</td>\n",
       "      <td>301</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iran criticizes who?</td>\n",
       "      <td>TEHRAN, Iran (CNN) -- Iran's parliament speake...</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "2  who did say South Africa did not issue a visa ...   \n",
       "4                      What frightened the families?   \n",
       "6                                     Who is hiring?   \n",
       "8                               Iran criticizes who?   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...          294        297  \n",
       "2  Johannesburg (CNN) -- Miffed by a visa delay t...          103        127  \n",
       "4  BAGHDAD, Iraq (CNN)  -- At least 6,000 Christi...          688        791  \n",
       "6  CNN affiliates report on where job seekers are...          301        324  \n",
       "8  TEHRAN, Iran (CNN) -- Iran's parliament speake...           63         97  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df.drop(columns=['validated_answers'])\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('a', 'h', 'm', '(', 'b')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = ''\n",
    "m = 0\n",
    "for col in ['question','story_text']:\n",
    "    for text in final[col]:\n",
    "        m = max(m, len(text))\n",
    "        full_text += text.lower()\n",
    "    print(m)\n",
    "    m=0\n",
    "\n",
    "# get the set of all characters\n",
    "characters = tuple(set(full_text))\n",
    "characters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'h': 1, 'm': 2, '(': 3, 'b': 4, '\\n': 5, 'y': 6, ' ': 7, '.': 8, 'g': 9, '4': 10, '2': 11, '6': 12, '-': 13, '$': 14, 'q': 15, 'v': 16, '5': 17, 'ñ': 18, 'c': 19, '*': 20, '3': 21, '8': 22, ':': 23, '[': 24, '_': 25, '7': 26, ',': 27, 'd': 28, '9': 29, 'â': 30, 'o': 31, 'j': 32, '\"': 33, '!': 34, ']': 35, 'w': 36, 'u': 37, \"'\": 38, '1': 39, '0': 40, 't': 41, 's': 42, 'f': 43, 'é': 44, 'ã': 45, 'n': 46, 'e': 47, 'z': 48, 'ë': 49, '&': 50, 'l': 51, 'r': 52, 'p': 53, '•': 54, ')': 55, '/': 56, '?': 57, 'i': 58, ';': 59, 'k': 60, 'x': 61, '»': 62, '+': 63, '©': 64, 'ú': 65}\n"
     ]
    }
   ],
   "source": [
    "# use enumeration to give the characters integer values\n",
    "int2char = dict(enumerate(characters))\n",
    "\n",
    "# create the look up dictionary from characters to the assigned integers\n",
    "char2int = {char: index for index, char in int2char.items()}\n",
    "print(char2int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_max = 68\n",
    "story_max = 7361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>294</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>103</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>688</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>301</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36,...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          story_text  start_truth  end_truth  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          294        297  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          103        127  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          688        791  \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          301        324  \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           63         97  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_start = False\n",
    "\n",
    "for i, row in final.iterrows():\n",
    "    for col, N in zip(['question','story_text'], [q_max, story_max]):\n",
    "        enc = np.zeros(N, dtype=np.int32)\n",
    "        \n",
    "        row[col] = np.array([char2int[char] for char in row[col].lower()])\n",
    "        l = min(N, len(row[col]))\n",
    "        if padding_start:\n",
    "            enc[:l] = row[col][:l]\n",
    "        else:\n",
    "            enc[N-l:] = row[col][:l]\n",
    "        final[col][i] = enc\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final[['question', 'story_text']], \n",
    "                                                    final[['start_truth','end_truth']], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 85, 170, 118, 148,  31, 112, 152, 226,  13, 138, 146,  39, 187,\n",
      "             54, 120,  22, 223,   6,  35, 109,  15, 183,  11,  94, 213, 159,\n",
      "            126, 225,  26,  66, 116,  63, 132,  48, 119, 224, 154,  18,  80,\n",
      "            220, 160, 174, 196, 105,  69,   2, 144,  42,   4,  47, 219,  40,\n",
      "            161, 211,  25, 139],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>story_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "85   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "170  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "148  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "31   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            story_text  \n",
       "85   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "170  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "148  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "31   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_truth</th>\n",
       "      <th>end_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2601</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1250</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1765</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1873</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_truth  end_truth\n",
       "85          2601       2606\n",
       "170         1250       1308\n",
       "118           64         98\n",
       "148         1765       1777\n",
       "31          1873       1907"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsQADataset(Dataset):\n",
    "    def __init__(self, X, y, N=400, padding_start=False):\n",
    "        self.y = y.values\n",
    "        self.question = X['question'].values\n",
    "        self.story_text =X['story_text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.question[idx], self.story_text[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsQADataset(X_train, y_train)\n",
    "test_ds = NewsQADataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 58, 46,  7,\n",
       "        36,  1,  0, 41,  7,  6, 47,  0, 52,  7, 28, 58, 28,  7,  4,  2, 36,\n",
       "         7, 47, 46, 41, 47, 52,  7, 41,  1, 47,  7, 42, 53, 31, 52, 41, 57],\n",
       "       dtype=int32),\n",
       " array([ 0,  0,  0, ...,  0, 28,  8], dtype=int32),\n",
       " array([2601, 2606]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 68]) torch.Size([8, 7361]) torch.Size([8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 36,  1,  0,\n",
       "          41,  7, 36,  0,  6,  7,  0, 52, 47,  7, 41, 47,  0,  2, 42,  7,  4, 47,\n",
       "          58, 46,  9,  7, 53, 52, 47, 53,  0, 52, 47, 28,  7, 43, 31, 52,  7, 43,\n",
       "           0,  2, 58, 51,  0, 52,  7, 19, 58, 52, 19, 37, 58, 41],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0, 36,  1,  0, 41,  7, 36, 58, 51, 51,  7, 46, 47, 47, 28,\n",
       "           7, 19, 52, 47,  0, 41, 58, 16, 47,  7, 28, 58, 53, 51, 31,  2,  0, 19,\n",
       "           6,  7,  0, 46, 28,  7, 19, 31, 37, 52,  0,  9, 47, 57],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 36,  1,  0, 41,  7, 28, 58,\n",
       "          28,  7, 41,  1, 47,  7, 52, 47, 53,  7, 42,  0,  6, 57],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 36,  1, 31, 42, 47,\n",
       "           7, 19,  0, 52,  7, 36,  0, 42,  7, 43, 31, 37, 46, 28],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0, 36,  1, 47, 46,  7, 28, 58, 28,  7, 52, 47,  4, 47, 51, 42,\n",
       "           7,  9,  0, 58, 46,  7, 19, 31, 46, 41, 52, 31, 51, 57],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0, 36,  1,  0, 41,  7, 28, 58, 28,  7, 41,  1, 47,  7, 42, 53,\n",
       "          31, 60, 47, 42,  2,  0, 46,  7, 42,  0,  6,  7,  0,  4, 31, 37, 41,  7,\n",
       "          41,  1, 47,  7, 53, 52, 47, 42, 58, 28, 47, 46, 41, 57],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 36,  1,  0, 41,  7,\n",
       "          16, 47, 52, 42, 58, 31, 46,  7, 31, 43,  7, 33,  1,  0, 46, 46,  0,  1,\n",
       "           7,  2, 31, 46, 41,  0, 46,  0, 33,  7, 28, 31, 47, 42,  7,  2, 58, 51,\n",
       "          47,  6,  7, 19,  6, 52, 37, 42,  7, 42, 41,  0, 52, 57],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          36,  1,  0, 41,  7, 58, 42,  7, 41,  1, 47,  7,  4, 47, 42, 41,  7, 19,\n",
       "          31, 37, 52, 42, 47,  7, 58, 46,  7, 58, 52,  0, 15, 57]],\n",
       "        dtype=torch.int32), tensor([[ 0,  0,  0,  ..., 47, 46, 28],\n",
       "         [ 0,  0,  0,  ..., 47, 42,  8],\n",
       "         [ 0,  0,  0,  ..., 58, 28,  8],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ..., 60,  8, 33],\n",
       "         [ 0,  0,  0,  ..., 51, 47,  8],\n",
       "         [ 0,  0,  0,  ..., 46, 28,  8]], dtype=torch.int32), tensor([[2551, 2572],\n",
       "         [ 672,  695],\n",
       "         [ 327,  386],\n",
       "         [ 761,  767],\n",
       "         [1125, 1130],\n",
       "         [1873, 1907],\n",
       "         [  58,   93],\n",
       "         [5096, 5183]]))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, y = next(iter(train_dl))\n",
    "print(x1.shape, x2.shape, y.shape)\n",
    "x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = torch.tanh(self.linear_i2h(combined))\n",
    "        output = self.linear_h2o(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, bash_size):\n",
    "        return torch.zeros(bash_size, self.hidden_size)\n",
    "    \n",
    "# This is the model being used. It is using character embeddings\n",
    "class CharEmbRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, output_size):\n",
    "        super(CharEmbRNN, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_i2h = nn.Linear(emb_size + hidden_size, hidden_size)\n",
    "        self.linear_h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.long()\n",
    "        x = self.emb(x)\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = torch.tanh(self.linear_i2h(combined))\n",
    "        output = self.linear_h2o(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, bash_size):\n",
    "        return torch.zeros(bash_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 66\n",
    "hidden_size = 100\n",
    "n_classes = 2\n",
    "emb_size = 10\n",
    "model = CharEmbRNN(vocab_size, emb_size, hidden_size, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've taken the functions from her last name classification model because that uses character-level embeddings as well. I'm using a naive version that just concats the question with the story and uses that as input into the RNN. I used that with regressing 2 outputs (start, end) and I got it to train but not sure how well it's actually doing. I think we correct way to do this is to treat it as a classification problem where each index of the story is a categroy and we use those predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.1, wd = 0.0001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, train_dl):\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "         # all zeros\n",
    "        loss = 0\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        batch = x.shape[0]\n",
    "        h = model.initHidden(batch)\n",
    "        \n",
    "        for t in range(x.shape[1]):\n",
    "            #print(x[:,t])\n",
    "            out, h = model(x[:,t], h)\n",
    "            #max_h = np.maximum(h.detach().numpy(), max_h)\n",
    "        \n",
    "        print(out)\n",
    "        print(y)\n",
    "        #loss = F.cross_entropy(out, y)\n",
    "        loss = criterion(out, y.float())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        #loss.backward(retain_graph=True)\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total\n",
    "\n",
    "def train_loop(model, lr, train_dl, val_dl, epochs=20):\n",
    "    optim = get_optimizer(model, lr =lr, wd = 0.0)\n",
    "    for i in range(epochs):\n",
    "        loss = train(model, optim, train_dl)\n",
    "        val_loss, val_acc = val_metric(model, val_dl)\n",
    "        if i%5 == 1: print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (loss, val_loss, val_acc))\n",
    "            \n",
    "def val_metric(model, val_dl):\n",
    "    criterion = nn.MSELoss()\n",
    "    model.eval()\n",
    "    x1, x2, y = next(iter(val_dl))\n",
    "    x = torch.cat((x1, x2), 1)\n",
    "    x = x.float()\n",
    "    y = y.long()\n",
    "    N = x.shape[0]\n",
    "    h = model.initHidden(N)\n",
    "    for t in range(x.shape[1]):\n",
    "        out, h = model(x[:,t], h)\n",
    "    loss = criterion(out, y.float())\n",
    "    _, pred = torch.max(out, 1)\n",
    "    print(out)\n",
    "    print(y)\n",
    "    #acc = pred.eq(y).sum().float()/N\n",
    "    return loss.item(), .22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2625, -0.0864],\n",
      "        [-0.3722, -0.1448],\n",
      "        [-0.2625, -0.0864],\n",
      "        [-0.1193, -0.0555],\n",
      "        [-0.2695, -0.0642],\n",
      "        [-0.2103, -0.0539],\n",
      "        [-0.2512, -0.1471],\n",
      "        [-0.0875, -0.0234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[   0,   16],\n",
      "        [  22,   32],\n",
      "        [ 122,  138],\n",
      "        [ 488,  603],\n",
      "        [1250, 1308],\n",
      "        [ 614,  649],\n",
      "        [1659, 1669],\n",
      "        [2197, 2493]])\n",
      "tensor([[ 0.6967,  0.5587],\n",
      "        [ 1.0325,  0.7371],\n",
      "        [-0.5078, -0.5837],\n",
      "        [ 1.5960,  2.0563],\n",
      "        [-0.6149, -0.4347],\n",
      "        [ 2.2503,  2.0067],\n",
      "        [ 1.0488,  0.7486],\n",
      "        [ 1.8871,  2.0774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 221,  232],\n",
      "        [ 688,  791],\n",
      "        [1714, 1721],\n",
      "        [ 346,  362],\n",
      "        [ 567,  588],\n",
      "        [5819, 5837],\n",
      "        [ 439,  504],\n",
      "        [ 470,  502]])\n",
      "tensor([[ 6.7597,  7.0826],\n",
      "        [ 8.4448,  8.2935],\n",
      "        [-6.2398, -6.1299],\n",
      "        [ 7.0281,  7.2302],\n",
      "        [-5.8660, -6.1211],\n",
      "        [ 6.7075,  6.9069],\n",
      "        [ 0.1541, -0.3349],\n",
      "        [-2.2964, -2.9833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3171, 3186],\n",
      "        [ 676,  703],\n",
      "        [2551, 2572],\n",
      "        [ 122,  130],\n",
      "        [ 581,  658],\n",
      "        [ 103,  127],\n",
      "        [  58,   93],\n",
      "        [2016, 2024]])\n",
      "tensor([[5.7249, 5.7982],\n",
      "        [6.2405, 6.2594],\n",
      "        [6.2410, 6.2597],\n",
      "        [5.8923, 6.0076],\n",
      "        [5.7470, 5.8099],\n",
      "        [6.2413, 6.2599],\n",
      "        [6.2407, 6.2595],\n",
      "        [6.2411, 6.2597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1873, 1907],\n",
      "        [1490, 1498],\n",
      "        [1409, 1501],\n",
      "        [ 290,  474],\n",
      "        [1603, 1668],\n",
      "        [ 242,  310],\n",
      "        [3798, 4072],\n",
      "        [ 260,  270]])\n",
      "tensor([[ 0.6621,  0.0488],\n",
      "        [ 0.6787,  0.0512],\n",
      "        [ 0.3404, -0.2831],\n",
      "        [ 0.6802,  0.0643],\n",
      "        [ 0.0379, -0.5522],\n",
      "        [ 0.4463, -0.1892],\n",
      "        [-0.6456, -0.7351],\n",
      "        [ 0.3405, -0.2830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 967, 1009],\n",
      "        [3802, 3830],\n",
      "        [1125, 1130],\n",
      "        [3859, 3877],\n",
      "        [ 555,  560],\n",
      "        [ 178,  190],\n",
      "        [  28,   49],\n",
      "        [2137, 2195]])\n",
      "tensor([[  5.2049,   4.6021],\n",
      "        [  5.3750,   4.7642],\n",
      "        [  5.1662,   4.6061],\n",
      "        [-10.4207, -10.3065],\n",
      "        [  5.1955,   4.6105],\n",
      "        [  5.1663,   4.6062],\n",
      "        [  5.3365,   4.7630],\n",
      "        [  5.1783,   4.6107]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 548,  551],\n",
      "        [1012, 1066],\n",
      "        [ 325,  356],\n",
      "        [  64,   98],\n",
      "        [5096, 5183],\n",
      "        [ 327,  386],\n",
      "        [3544, 3676],\n",
      "        [2601, 2606]])\n",
      "tensor([[ 11.4664,  11.0049],\n",
      "        [ 15.5403,  15.6701],\n",
      "        [ -3.0038,  -2.7064],\n",
      "        [-11.1537, -11.0160],\n",
      "        [ -8.4119,  -7.4262],\n",
      "        [-10.1592, -10.0132],\n",
      "        [ -9.1999,  -8.1663],\n",
      "        [-11.1537, -11.0160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 594,  604],\n",
      "        [2989, 3069],\n",
      "        [2876, 2894],\n",
      "        [1306, 1314],\n",
      "        [ 301,  324],\n",
      "        [ 672,  695],\n",
      "        [1765, 1777],\n",
      "        [ 761,  767]])\n"
     ]
    }
   ],
   "source": [
    "optim = get_optimizer(model)\n",
    "\n",
    "loss = train(model, optim, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49.6686,  49.1719],\n",
      "        [ 49.9820,  49.4869],\n",
      "        [ 49.9940,  49.4994],\n",
      "        [-45.9037, -45.6669],\n",
      "        [ 49.9866,  49.4915],\n",
      "        [ 49.9820,  49.4869],\n",
      "        [ 49.9820,  49.4869],\n",
      "        [ 49.6834,  49.1869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 221,  232],\n",
      "        [3798, 4072],\n",
      "        [ 346,  362],\n",
      "        [3171, 3186],\n",
      "        [ 672,  695],\n",
      "        [ 260,  270],\n",
      "        [ 242,  310],\n",
      "        [  22,   32]])\n",
      "tensor([[48.7060, 48.2194],\n",
      "        [50.8731, 50.3818],\n",
      "        [50.8582, 50.3626],\n",
      "        [50.8679, 50.3725],\n",
      "        [49.9357, 49.4450],\n",
      "        [49.4767, 49.0022],\n",
      "        [50.8811, 50.3858],\n",
      "        [50.8717, 50.3763]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1306, 1314],\n",
      "        [ 488,  603],\n",
      "        [  58,   93],\n",
      "        [3859, 3877],\n",
      "        [ 290,  474],\n",
      "        [ 581,  658],\n",
      "        [ 548,  551],\n",
      "        [ 688,  791]])\n",
      "tensor([[51.5992, 51.1154],\n",
      "        [51.9000, 51.4174],\n",
      "        [49.8441, 49.3521],\n",
      "        [51.8996, 51.4170],\n",
      "        [51.5704, 51.0862],\n",
      "        [51.9014, 51.4188],\n",
      "        [51.8934, 51.4108],\n",
      "        [51.8944, 51.4117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1765, 1777],\n",
      "        [ 325,  356],\n",
      "        [2551, 2572],\n",
      "        [3802, 3830],\n",
      "        [  28,   49],\n",
      "        [1250, 1308],\n",
      "        [ 967, 1009],\n",
      "        [ 178,  190]])\n",
      "tensor([[52.8545, 52.3822],\n",
      "        [52.7706, 52.2975],\n",
      "        [52.8537, 52.3814],\n",
      "        [52.7709, 52.2978],\n",
      "        [52.8539, 52.3816],\n",
      "        [52.7708, 52.2977],\n",
      "        [52.8556, 52.3833],\n",
      "        [52.8534, 52.3811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 676,  703],\n",
      "        [  64,   98],\n",
      "        [1012, 1066],\n",
      "        [1873, 1907],\n",
      "        [3544, 3676],\n",
      "        [1603, 1668],\n",
      "        [5096, 5183],\n",
      "        [2989, 3069]])\n",
      "tensor([[53.7921, 53.3265],\n",
      "        [53.7672, 53.3013],\n",
      "        [53.7921, 53.3265],\n",
      "        [53.7921, 53.3265],\n",
      "        [53.5138, 53.0419],\n",
      "        [53.7922, 53.3266],\n",
      "        [53.7922, 53.3266],\n",
      "        [53.7923, 53.3267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1409, 1501],\n",
      "        [1714, 1721],\n",
      "        [ 122,  138],\n",
      "        [2016, 2024],\n",
      "        [ 761,  767],\n",
      "        [ 555,  560],\n",
      "        [ 614,  649],\n",
      "        [ 327,  386]])\n",
      "tensor([[54.7177, 54.2571],\n",
      "        [54.7177, 54.2571],\n",
      "        [54.7177, 54.2571],\n",
      "        [54.7177, 54.2571],\n",
      "        [54.7177, 54.2571],\n",
      "        [54.6136, 54.1496],\n",
      "        [54.7177, 54.2571],\n",
      "        [54.7177, 54.2571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[5819, 5837],\n",
      "        [ 122,  130],\n",
      "        [2137, 2195],\n",
      "        [1490, 1498],\n",
      "        [2601, 2606],\n",
      "        [ 567,  588],\n",
      "        [   0,   16],\n",
      "        [ 594,  604]])\n",
      "tensor([[55.6680, 55.2107],\n",
      "        [55.6722, 55.2148],\n",
      "        [55.6722, 55.2148],\n",
      "        [55.6722, 55.2148],\n",
      "        [55.6722, 55.2148],\n",
      "        [55.6718, 55.2145],\n",
      "        [55.6722, 55.2148],\n",
      "        [55.6722, 55.2148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 301,  324],\n",
      "        [ 103,  127],\n",
      "        [1125, 1130],\n",
      "        [ 439,  504],\n",
      "        [2876, 2894],\n",
      "        [2197, 2493],\n",
      "        [ 470,  502],\n",
      "        [1659, 1669]])\n",
      "tensor([[56.5817, 56.1263],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6239, 56.1709],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.5825, 56.1274],\n",
      "        [56.6239, 56.1709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "tensor([[56.5817, 56.1263],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6263, 56.1732],\n",
      "        [56.6260, 56.1730],\n",
      "        [56.6239, 56.1709],\n",
      "        [56.6263, 56.1732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2551, 2572],\n",
      "        [ 325,  356],\n",
      "        [2137, 2195],\n",
      "        [ 242,  310],\n",
      "        [1012, 1066],\n",
      "        [ 346,  362],\n",
      "        [ 221,  232],\n",
      "        [5096, 5183]])\n",
      "tensor([[57.5963, 57.1465],\n",
      "        [57.5963, 57.1465],\n",
      "        [57.5963, 57.1465],\n",
      "        [57.5961, 57.1463],\n",
      "        [57.5947, 57.1449],\n",
      "        [57.5947, 57.1449],\n",
      "        [57.5947, 57.1449],\n",
      "        [57.5947, 57.1449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 327,  386],\n",
      "        [ 688,  791],\n",
      "        [5819, 5837],\n",
      "        [2197, 2493],\n",
      "        [1603, 1668],\n",
      "        [  64,   98],\n",
      "        [1873, 1907],\n",
      "        [  22,   32]])\n",
      "tensor([[ 58.5451,  58.0960],\n",
      "        [ 58.5808,  58.1345],\n",
      "        [ 58.5808,  58.1345],\n",
      "        [ 58.5451,  58.0960],\n",
      "        [-51.8396, -51.6872],\n",
      "        [ 58.5794,  58.1330],\n",
      "        [ 58.5808,  58.1345],\n",
      "        [ 58.5808,  58.1345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 761,  767],\n",
      "        [ 260,  270],\n",
      "        [1250, 1308],\n",
      "        [ 567,  588],\n",
      "        [3171, 3186],\n",
      "        [  28,   49],\n",
      "        [ 470,  502],\n",
      "        [ 672,  695]])\n",
      "tensor([[59.4699, 59.0287],\n",
      "        [59.4697, 59.0285],\n",
      "        [59.4699, 59.0287],\n",
      "        [59.4699, 59.0287],\n",
      "        [59.4699, 59.0287],\n",
      "        [59.4699, 59.0287],\n",
      "        [59.4699, 59.0287],\n",
      "        [59.4699, 59.0287]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1125, 1130],\n",
      "        [ 488,  603],\n",
      "        [ 103,  127],\n",
      "        [ 122,  138],\n",
      "        [ 614,  649],\n",
      "        [1490, 1498],\n",
      "        [1409, 1501],\n",
      "        [1659, 1669]])\n",
      "tensor([[60.3486, 59.9127],\n",
      "        [60.3486, 59.9127],\n",
      "        [60.3486, 59.9127],\n",
      "        [60.3453, 59.9095],\n",
      "        [60.3142, 59.8780],\n",
      "        [60.3486, 59.9127],\n",
      "        [60.3486, 59.9127],\n",
      "        [60.3458, 59.9100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 122,  130],\n",
      "        [ 178,  190],\n",
      "        [ 967, 1009],\n",
      "        [1765, 1777],\n",
      "        [ 581,  658],\n",
      "        [3859, 3877],\n",
      "        [3798, 4072],\n",
      "        [1714, 1721]])\n",
      "tensor([[61.2609, 60.8293],\n",
      "        [61.2609, 60.8293],\n",
      "        [61.2609, 60.8293],\n",
      "        [61.2609, 60.8293],\n",
      "        [61.1783, 60.7438],\n",
      "        [61.2569, 60.8258],\n",
      "        [61.2609, 60.8293],\n",
      "        [61.2609, 60.8293]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2989, 3069],\n",
      "        [ 548,  551],\n",
      "        [3802, 3830],\n",
      "        [ 676,  703],\n",
      "        [1306, 1314],\n",
      "        [ 290,  474],\n",
      "        [ 439,  504],\n",
      "        [ 594,  604]])\n",
      "tensor([[62.1869, 61.7595],\n",
      "        [62.1869, 61.7595],\n",
      "        [62.1869, 61.7595],\n",
      "        [62.1869, 61.7595],\n",
      "        [62.1869, 61.7595],\n",
      "        [62.1869, 61.7595],\n",
      "        [62.1814, 61.7550],\n",
      "        [62.1869, 61.7595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 555,  560],\n",
      "        [   0,   16],\n",
      "        [  58,   93],\n",
      "        [2601, 2606],\n",
      "        [2016, 2024],\n",
      "        [3544, 3676],\n",
      "        [ 301,  324],\n",
      "        [2876, 2894]])\n",
      "tensor([[62.9777, 62.5540],\n",
      "        [63.1320, 62.7073],\n",
      "        [63.1320, 62.7073],\n",
      "        [63.1236, 62.7009],\n",
      "        [63.1320, 62.7073],\n",
      "        [63.1320, 62.7073],\n",
      "        [62.9043, 62.4968],\n",
      "        [63.1236, 62.7009]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "train loss 3528641.080 val loss 1790930.625 and val accuracy 0.220\n",
      "tensor([[63.1320, 62.7073],\n",
      "        [63.1236, 62.7009],\n",
      "        [63.1301, 62.7060],\n",
      "        [63.1320, 62.7073],\n",
      "        [63.1320, 62.7073],\n",
      "        [63.1236, 62.7009],\n",
      "        [62.9777, 62.5540],\n",
      "        [63.1320, 62.7073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[  58,   93],\n",
      "        [  64,   98],\n",
      "        [ 488,  603],\n",
      "        [1490, 1498],\n",
      "        [2016, 2024],\n",
      "        [ 301,  324],\n",
      "        [ 761,  767],\n",
      "        [1659, 1669]])\n",
      "tensor([[64.0566, 63.6345],\n",
      "        [64.0566, 63.6345],\n",
      "        [64.0439, 63.6253],\n",
      "        [64.0439, 63.6253],\n",
      "        [64.0566, 63.6345],\n",
      "        [64.0566, 63.6345],\n",
      "        [64.0566, 63.6345],\n",
      "        [64.0566, 63.6345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 122,  130],\n",
      "        [1012, 1066],\n",
      "        [ 290,  474],\n",
      "        [  22,   32],\n",
      "        [ 967, 1009],\n",
      "        [ 594,  604],\n",
      "        [3802, 3830],\n",
      "        [ 103,  127]])\n",
      "tensor([[64.6653, 64.2571],\n",
      "        [64.9644, 64.5458],\n",
      "        [64.9594, 64.5424],\n",
      "        [64.9644, 64.5458],\n",
      "        [64.9644, 64.5458],\n",
      "        [64.9455, 64.5323],\n",
      "        [64.9644, 64.5458],\n",
      "        [64.9644, 64.5458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1306, 1314],\n",
      "        [2601, 2606],\n",
      "        [ 346,  362],\n",
      "        [ 327,  386],\n",
      "        [ 439,  504],\n",
      "        [ 221,  232],\n",
      "        [2989, 3069],\n",
      "        [ 548,  551]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[65.8734, 65.4576],\n",
      "        [65.8488, 65.4401],\n",
      "        [65.8734, 65.4576],\n",
      "        [65.8489, 65.4402],\n",
      "        [65.8734, 65.4576],\n",
      "        [65.8488, 65.4401],\n",
      "        [65.8734, 65.4576],\n",
      "        [65.8734, 65.4576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1250, 1308],\n",
      "        [1603, 1668],\n",
      "        [ 470,  502],\n",
      "        [1714, 1721],\n",
      "        [ 242,  310],\n",
      "        [  28,   49],\n",
      "        [2876, 2894],\n",
      "        [1125, 1130]])\n",
      "tensor([[66.7878, 66.3743],\n",
      "        [66.7878, 66.3743],\n",
      "        [66.7878, 66.3743],\n",
      "        [66.7878, 66.3743],\n",
      "        [66.7878, 66.3743],\n",
      "        [66.7623, 66.3556],\n",
      "        [66.7878, 66.3743],\n",
      "        [66.7878, 66.3743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 614,  649],\n",
      "        [3544, 3676],\n",
      "        [ 260,  270],\n",
      "        [ 122,  138],\n",
      "        [3798, 4072],\n",
      "        [1873, 1907],\n",
      "        [5096, 5183],\n",
      "        [3859, 3877]])\n",
      "tensor([[ 67.7544,  67.3427],\n",
      "        [-41.2813, -41.3490],\n",
      "        [ 67.7544,  67.3427],\n",
      "        [ 67.7544,  67.3427],\n",
      "        [ 67.7544,  67.3427],\n",
      "        [ 67.7297,  67.3238],\n",
      "        [ 67.3097,  66.9752],\n",
      "        [ 67.7441,  67.3353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 325,  356],\n",
      "        [3171, 3186],\n",
      "        [2137, 2195],\n",
      "        [ 672,  695],\n",
      "        [5819, 5837],\n",
      "        [1765, 1777],\n",
      "        [ 581,  658],\n",
      "        [2197, 2493]])\n",
      "tensor([[68.7287, 68.3194],\n",
      "        [68.7287, 68.3194],\n",
      "        [68.1708, 67.7860],\n",
      "        [68.7287, 68.3194],\n",
      "        [68.1708, 67.7860],\n",
      "        [68.7287, 68.3194],\n",
      "        [68.7287, 68.3194],\n",
      "        [68.7287, 68.3194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 178,  190],\n",
      "        [1409, 1501],\n",
      "        [ 567,  588],\n",
      "        [ 688,  791],\n",
      "        [2551, 2572],\n",
      "        [ 555,  560],\n",
      "        [ 676,  703],\n",
      "        [   0,   16]])\n",
      "tensor([[69.2853, 68.8938],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6604, 69.2563],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [68.8727, 68.5722],\n",
      "        [69.6604, 69.2563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "tensor([[69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.6752, 69.2687],\n",
      "        [69.2853, 68.8938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[5096, 5183],\n",
      "        [3859, 3877],\n",
      "        [ 325,  356],\n",
      "        [  58,   93],\n",
      "        [2137, 2195],\n",
      "        [3802, 3830],\n",
      "        [ 594,  604],\n",
      "        [ 567,  588]])\n",
      "tensor([[70.6594, 70.2544],\n",
      "        [70.6594, 70.2544],\n",
      "        [70.6594, 70.2544],\n",
      "        [70.6594, 70.2544],\n",
      "        [70.6594, 70.2544],\n",
      "        [70.6594, 70.2544],\n",
      "        [70.6475, 70.2440],\n",
      "        [70.6594, 70.2544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3798, 4072],\n",
      "        [2016, 2024],\n",
      "        [ 122,  130],\n",
      "        [ 688,  791],\n",
      "        [ 439,  504],\n",
      "        [ 555,  560],\n",
      "        [ 301,  324],\n",
      "        [ 327,  386]])\n",
      "tensor([[ 71.6189,  71.2187],\n",
      "        [ 71.6149,  71.2144],\n",
      "        [ 71.6266,  71.2249],\n",
      "        [ 71.6266,  71.2249],\n",
      "        [ 71.6266,  71.2249],\n",
      "        [-35.7549, -35.9444],\n",
      "        [ 71.6266,  71.2249],\n",
      "        [ 71.6266,  71.2249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 488,  603],\n",
      "        [ 221,  232],\n",
      "        [ 122,  138],\n",
      "        [5819, 5837],\n",
      "        [ 672,  695],\n",
      "        [3171, 3186],\n",
      "        [ 967, 1009],\n",
      "        [2876, 2894]])\n",
      "tensor([[72.5720, 72.1740],\n",
      "        [72.5780, 72.1803],\n",
      "        [72.3867, 71.9906],\n",
      "        [72.5780, 72.1803],\n",
      "        [72.5866, 72.1875],\n",
      "        [72.5866, 72.1875],\n",
      "        [72.5866, 72.1875],\n",
      "        [72.5720, 72.1740]], grad_fn=<AddmmBackward>)\n",
      "tensor([[  22,   32],\n",
      "        [2197, 2493],\n",
      "        [2551, 2572],\n",
      "        [ 346,  362],\n",
      "        [   0,   16],\n",
      "        [3544, 3676],\n",
      "        [ 242,  310],\n",
      "        [ 290,  474]])\n",
      "tensor([[73.5396, 73.1460],\n",
      "        [73.5396, 73.1460],\n",
      "        [73.5201, 73.1275],\n",
      "        [73.1872, 72.8365],\n",
      "        [73.5396, 73.1460],\n",
      "        [73.5396, 73.1460],\n",
      "        [73.5200, 73.1274],\n",
      "        [73.5396, 73.1460]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2601, 2606],\n",
      "        [1012, 1066],\n",
      "        [1765, 1777],\n",
      "        [ 581,  658],\n",
      "        [2989, 3069],\n",
      "        [1659, 1669],\n",
      "        [  28,   49],\n",
      "        [1250, 1308]])\n",
      "tensor([[74.5053, 74.1161],\n",
      "        [74.5053, 74.1161],\n",
      "        [74.5053, 74.1161],\n",
      "        [74.5053, 74.1161],\n",
      "        [74.5053, 74.1161],\n",
      "        [74.5053, 74.1161],\n",
      "        [74.4779, 74.0899],\n",
      "        [74.5053, 74.1161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1490, 1498],\n",
      "        [1409, 1501],\n",
      "        [ 103,  127],\n",
      "        [1125, 1130],\n",
      "        [ 260,  270],\n",
      "        [ 548,  551],\n",
      "        [1714, 1721],\n",
      "        [ 614,  649]])\n",
      "tensor([[75.4101, 75.0258],\n",
      "        [75.4480, 75.0625],\n",
      "        [75.4102, 75.0259],\n",
      "        [75.4480, 75.0625],\n",
      "        [75.4480, 75.0625],\n",
      "        [75.4102, 75.0259],\n",
      "        [75.2227, 74.8409],\n",
      "        [75.2227, 74.8409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[  64,   98],\n",
      "        [ 676,  703],\n",
      "        [1873, 1907],\n",
      "        [ 178,  190],\n",
      "        [ 470,  502],\n",
      "        [1603, 1668],\n",
      "        [1306, 1314],\n",
      "        [ 761,  767]])\n",
      "tensor([[76.1381, 75.7604],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3285, 75.9474],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [75.2228, 74.8945],\n",
      "        [76.3285, 75.9474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "tensor([[76.3676, 75.9852],\n",
      "        [76.1381, 75.7604],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3676, 75.9852],\n",
      "        [76.3285, 75.9474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 242,  310],\n",
      "        [ 567,  588],\n",
      "        [ 614,  649],\n",
      "        [ 548,  551],\n",
      "        [ 688,  791],\n",
      "        [ 103,  127],\n",
      "        [ 439,  504],\n",
      "        [1603, 1668]])\n",
      "tensor([[77.2474, 76.8702],\n",
      "        [77.2474, 76.8702],\n",
      "        [77.2474, 76.8702],\n",
      "        [77.2474, 76.8702],\n",
      "        [77.2474, 76.8702],\n",
      "        [77.2097, 76.8336],\n",
      "        [77.2474, 76.8702],\n",
      "        [77.0140, 76.6423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[5819, 5837],\n",
      "        [1012, 1066],\n",
      "        [5096, 5183],\n",
      "        [ 122,  130],\n",
      "        [ 470,  502],\n",
      "        [ 221,  232],\n",
      "        [3802, 3830],\n",
      "        [1306, 1314]])\n",
      "tensor([[78.1867, 77.8120],\n",
      "        [77.9526, 77.5843],\n",
      "        [78.1867, 77.8120],\n",
      "        [78.1564, 77.7829],\n",
      "        [78.1867, 77.8120],\n",
      "        [78.1867, 77.8120],\n",
      "        [78.1564, 77.7829],\n",
      "        [78.1867, 77.8120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2601, 2606],\n",
      "        [2551, 2572],\n",
      "        [ 594,  604],\n",
      "        [2197, 2493],\n",
      "        [1250, 1308],\n",
      "        [1409, 1501],\n",
      "        [ 346,  362],\n",
      "        [ 325,  356]])\n",
      "tensor([[79.1358, 78.7647],\n",
      "        [79.1052, 78.7349],\n",
      "        [79.1358, 78.7647],\n",
      "        [79.1052, 78.7349],\n",
      "        [79.1052, 78.7349],\n",
      "        [79.1358, 78.7647],\n",
      "        [79.1052, 78.7349],\n",
      "        [79.1358, 78.7647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 178,  190],\n",
      "        [1765, 1777],\n",
      "        [2016, 2024],\n",
      "        [  22,   32],\n",
      "        [ 301,  324],\n",
      "        [   0,   16],\n",
      "        [  64,   98],\n",
      "        [1125, 1130]])\n",
      "tensor([[80.0471, 79.6788],\n",
      "        [80.0471, 79.6788],\n",
      "        [80.0471, 79.6788],\n",
      "        [80.0471, 79.6788],\n",
      "        [80.0471, 79.6788],\n",
      "        [80.0471, 79.6788],\n",
      "        [80.0174, 79.6498],\n",
      "        [80.0174, 79.6498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3544, 3676],\n",
      "        [  58,   93],\n",
      "        [2876, 2894],\n",
      "        [1490, 1498],\n",
      "        [ 122,  138],\n",
      "        [ 676,  703],\n",
      "        [1873, 1907],\n",
      "        [  28,   49]])\n",
      "tensor([[80.9365, 80.5711],\n",
      "        [80.9675, 80.6014],\n",
      "        [80.9675, 80.6014],\n",
      "        [80.9675, 80.6014],\n",
      "        [80.9675, 80.6014],\n",
      "        [80.9675, 80.6014],\n",
      "        [80.7301, 80.3721],\n",
      "        [79.6416, 79.3222]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 290,  474],\n",
      "        [ 327,  386],\n",
      "        [ 555,  560],\n",
      "        [ 967, 1009],\n",
      "        [ 672,  695],\n",
      "        [3798, 4072],\n",
      "        [ 761,  767],\n",
      "        [ 581,  658]])\n",
      "tensor([[-38.6091, -38.7905],\n",
      "        [ 81.8743,  81.5136],\n",
      "        [ 81.8743,  81.5136],\n",
      "        [ 81.8743,  81.5136],\n",
      "        [ 81.8743,  81.5136],\n",
      "        [ 81.8217,  81.4627],\n",
      "        [ 81.8743,  81.5136],\n",
      "        [ 81.8441,  81.4840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3171, 3186],\n",
      "        [2989, 3069],\n",
      "        [ 260,  270],\n",
      "        [1659, 1669],\n",
      "        [2137, 2195],\n",
      "        [ 488,  603],\n",
      "        [3859, 3877],\n",
      "        [1714, 1721]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[82.5688, 82.2203],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7675, 82.4116],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7967, 82.4402],\n",
      "        [79.9891, 79.7223],\n",
      "        [82.7675, 82.4116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "tensor([[82.7967, 82.4402],\n",
      "        [82.5688, 82.2203],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7675, 82.4115],\n",
      "        [82.7675, 82.4115],\n",
      "        [82.7967, 82.4402],\n",
      "        [82.7439, 82.3892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 178,  190],\n",
      "        [ 567,  588],\n",
      "        [1409, 1501],\n",
      "        [1125, 1130],\n",
      "        [1603, 1668],\n",
      "        [  22,   32],\n",
      "        [1490, 1498],\n",
      "        [ 488,  603]])\n",
      "tensor([[83.6961, 83.3444],\n",
      "        [83.6961, 83.3444],\n",
      "        [83.6961, 83.3444],\n",
      "        [83.6961, 83.3444],\n",
      "        [83.6961, 83.3444],\n",
      "        [83.6688, 83.3176],\n",
      "        [83.6961, 83.3444],\n",
      "        [83.6961, 83.3444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3544, 3676],\n",
      "        [ 676,  703],\n",
      "        [ 122,  138],\n",
      "        [ 327,  386],\n",
      "        [ 555,  560],\n",
      "        [  64,   98],\n",
      "        [2601, 2606],\n",
      "        [ 242,  310]])\n",
      "tensor([[84.5859, 84.2392],\n",
      "        [84.5859, 84.2392],\n",
      "        [84.5859, 84.2392],\n",
      "        [84.5358, 84.1908],\n",
      "        [84.5859, 84.2392],\n",
      "        [84.5859, 84.2392],\n",
      "        [83.3008, 83.0035],\n",
      "        [84.5859, 84.2392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 470,  502],\n",
      "        [1250, 1308],\n",
      "        [1012, 1066],\n",
      "        [2197, 2493],\n",
      "        [ 103,  127],\n",
      "        [ 122,  130],\n",
      "        [ 581,  658],\n",
      "        [ 594,  604]])\n",
      "tensor([[85.4511, 85.1122],\n",
      "        [85.4511, 85.1122],\n",
      "        [85.4511, 85.1122],\n",
      "        [85.4511, 85.1122],\n",
      "        [85.4289, 85.0905],\n",
      "        [85.4511, 85.1122],\n",
      "        [85.4290, 85.0906],\n",
      "        [85.2279, 84.8957]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 967, 1009],\n",
      "        [2137, 2195],\n",
      "        [2876, 2894],\n",
      "        [3798, 4072],\n",
      "        [1765, 1777],\n",
      "        [2016, 2024],\n",
      "        [ 221,  232],\n",
      "        [1306, 1314]])\n",
      "tensor([[86.1325, 85.8053],\n",
      "        [86.3460, 86.0139],\n",
      "        [86.3460, 86.0139],\n",
      "        [86.3460, 86.0139],\n",
      "        [86.3647, 86.0321],\n",
      "        [86.3647, 86.0321],\n",
      "        [86.3647, 86.0321],\n",
      "        [86.1325, 85.8053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 761,  767],\n",
      "        [ 301,  324],\n",
      "        [1714, 1721],\n",
      "        [  28,   49],\n",
      "        [ 688,  791],\n",
      "        [3859, 3877],\n",
      "        [ 614,  649],\n",
      "        [2551, 2572]])\n",
      "tensor([[ 87.2709,  86.9436],\n",
      "        [ 87.2863,  86.9586],\n",
      "        [ 87.2863,  86.9586],\n",
      "        [ 87.2863,  86.9586],\n",
      "        [ 87.2863,  86.9586],\n",
      "        [ 87.2526,  86.9254],\n",
      "        [ 87.2863,  86.9586],\n",
      "        [-37.8104, -38.2088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1873, 1907],\n",
      "        [ 548,  551],\n",
      "        [3802, 3830],\n",
      "        [   0,   16],\n",
      "        [ 672,  695],\n",
      "        [ 346,  362],\n",
      "        [2989, 3069],\n",
      "        [3171, 3186]])\n",
      "tensor([[88.2000, 87.8760],\n",
      "        [88.2000, 87.8760],\n",
      "        [88.2000, 87.8760],\n",
      "        [88.2000, 87.8760],\n",
      "        [88.1860, 87.8624],\n",
      "        [88.2000, 87.8760],\n",
      "        [88.2000, 87.8760],\n",
      "        [88.2000, 87.8760]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 439,  504],\n",
      "        [ 260,  270],\n",
      "        [5096, 5183],\n",
      "        [5819, 5837],\n",
      "        [ 290,  474],\n",
      "        [1659, 1669],\n",
      "        [ 325,  356],\n",
      "        [  58,   93]])\n",
      "tensor([[88.7995, 88.4794],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1340, 88.8136],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1480, 88.8272],\n",
      "        [85.0101, 84.6944],\n",
      "        [89.1340, 88.8136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "tensor([[89.1480, 88.8272],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1340, 88.8136],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1480, 88.8272],\n",
      "        [88.0313, 87.7092],\n",
      "        [89.1480, 88.8272],\n",
      "        [89.1480, 88.8272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 260,  270],\n",
      "        [ 688,  791],\n",
      "        [ 290,  474],\n",
      "        [ 548,  551],\n",
      "        [2989, 3069],\n",
      "        [ 581,  658],\n",
      "        [5096, 5183],\n",
      "        [ 594,  604]])\n",
      "tensor([[90.1044, 89.7879],\n",
      "        [90.0683, 89.7513],\n",
      "        [90.1044, 89.7879],\n",
      "        [90.0904, 89.7744],\n",
      "        [89.7077, 89.3922],\n",
      "        [89.7077, 89.3922],\n",
      "        [90.1044, 89.7879],\n",
      "        [90.1044, 89.7879]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3798, 4072],\n",
      "        [ 346,  362],\n",
      "        [2601, 2606],\n",
      "        [1765, 1777],\n",
      "        [ 567,  588],\n",
      "        [1306, 1314],\n",
      "        [2137, 2195],\n",
      "        [1012, 1066]])\n",
      "tensor([[-37.8516, -38.3331],\n",
      "        [ 91.0870,  90.7744],\n",
      "        [ 91.0870,  90.7744],\n",
      "        [ 91.0870,  90.7744],\n",
      "        [ 91.0870,  90.7744],\n",
      "        [ 91.0870,  90.7744],\n",
      "        [ 91.0743,  90.7622],\n",
      "        [ 91.0742,  90.7622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[3171, 3186],\n",
      "        [ 470,  502],\n",
      "        [ 122,  130],\n",
      "        [1659, 1669],\n",
      "        [  58,   93],\n",
      "        [3802, 3830],\n",
      "        [1714, 1721],\n",
      "        [1603, 1668]])\n",
      "tensor([[92.0236, 91.7136],\n",
      "        [92.0481, 91.7384],\n",
      "        [92.0235, 91.7136],\n",
      "        [92.0362, 91.7270],\n",
      "        [92.0481, 91.7384],\n",
      "        [92.0481, 91.7384],\n",
      "        [92.0481, 91.7384],\n",
      "        [92.0481, 91.7384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 488,  603],\n",
      "        [1250, 1308],\n",
      "        [2197, 2493],\n",
      "        [  64,   98],\n",
      "        [   0,   16],\n",
      "        [ 178,  190],\n",
      "        [ 672,  695],\n",
      "        [2016, 2024]])\n",
      "tensor([[92.9693, 92.6658],\n",
      "        [92.9805, 92.6765],\n",
      "        [92.9805, 92.6765],\n",
      "        [92.9805, 92.6765],\n",
      "        [92.6546, 92.3570],\n",
      "        [92.9805, 92.6765],\n",
      "        [92.9805, 92.6765],\n",
      "        [92.9805, 92.6765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1873, 1907],\n",
      "        [ 676,  703],\n",
      "        [ 122,  138],\n",
      "        [ 555,  560],\n",
      "        [ 761,  767],\n",
      "        [5819, 5837],\n",
      "        [1409, 1501],\n",
      "        [ 103,  127]])\n",
      "tensor([[93.9252, 93.6250],\n",
      "        [93.9148, 93.6152],\n",
      "        [93.9252, 93.6250],\n",
      "        [93.9252, 93.6250],\n",
      "        [93.9148, 93.6152],\n",
      "        [93.9252, 93.6250],\n",
      "        [93.6293, 93.3366],\n",
      "        [93.9148, 93.6152]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 439,  504],\n",
      "        [ 301,  324],\n",
      "        [1490, 1498],\n",
      "        [ 967, 1009],\n",
      "        [  28,   49],\n",
      "        [2876, 2894],\n",
      "        [2551, 2572],\n",
      "        [ 221,  232]])\n",
      "tensor([[94.8603, 94.5631],\n",
      "        [94.8603, 94.5631],\n",
      "        [94.8603, 94.5631],\n",
      "        [94.8603, 94.5631],\n",
      "        [94.8603, 94.5631],\n",
      "        [94.8603, 94.5631],\n",
      "        [94.8519, 94.5551],\n",
      "        [94.8603, 94.5631]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1125, 1130],\n",
      "        [ 327,  386],\n",
      "        [ 242,  310],\n",
      "        [ 325,  356],\n",
      "        [ 614,  649],\n",
      "        [3859, 3877],\n",
      "        [  22,   32],\n",
      "        [3544, 3676]])\n",
      "tensor([[95.6154, 95.3270],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7898, 95.4959],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [91.0626, 90.8289],\n",
      "        [95.7898, 95.4959]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2585, 2646],\n",
      "        [ 294,  297],\n",
      "        [ 465,  476],\n",
      "        [1981, 1996],\n",
      "        [ 252,  273],\n",
      "        [1839, 1876],\n",
      "        [ 644,  758],\n",
      "        [ 499,  543]])\n",
      "train loss 3448091.232 val loss 1725525.125 and val accuracy 0.220\n",
      "tensor([[95.7971, 95.5028],\n",
      "        [95.7880, 95.4937],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.7971, 95.5028],\n",
      "        [95.6154, 95.3270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2876, 2894],\n",
      "        [ 346,  362],\n",
      "        [ 103,  127],\n",
      "        [ 967, 1009],\n",
      "        [ 327,  386],\n",
      "        [ 672,  695],\n",
      "        [3859, 3877],\n",
      "        [ 761,  767]])\n",
      "tensor([[96.7341, 96.4415],\n",
      "        [96.5815, 96.2942],\n",
      "        [96.7341, 96.4415],\n",
      "        [96.7341, 96.4415],\n",
      "        [96.7341, 96.4415],\n",
      "        [96.7341, 96.4415],\n",
      "        [96.5815, 96.2942],\n",
      "        [96.7341, 96.4415]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1490, 1498],\n",
      "        [2551, 2572],\n",
      "        [2989, 3069],\n",
      "        [3798, 4072],\n",
      "        [ 470,  502],\n",
      "        [2016, 2024],\n",
      "        [ 567,  588],\n",
      "        [ 325,  356]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[97.7057, 97.4146],\n",
      "        [97.7057, 97.4146],\n",
      "        [97.7057, 97.4146],\n",
      "        [97.7057, 97.4146],\n",
      "        [97.1695, 96.8885],\n",
      "        [97.7057, 97.4146],\n",
      "        [97.7000, 97.4092],\n",
      "        [97.7057, 97.4146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 122,  138],\n",
      "        [1012, 1066],\n",
      "        [1659, 1669],\n",
      "        [ 555,  560],\n",
      "        [ 581,  658],\n",
      "        [ 178,  190],\n",
      "        [  28,   49],\n",
      "        [ 242,  310]])\n",
      "tensor([[98.6239, 98.3355],\n",
      "        [98.6187, 98.3306],\n",
      "        [98.6187, 98.3306],\n",
      "        [98.6185, 98.3303],\n",
      "        [98.6239, 98.3355],\n",
      "        [98.5152, 98.2306],\n",
      "        [98.6187, 98.3306],\n",
      "        [98.6239, 98.3355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2601, 2606],\n",
      "        [ 290,  474],\n",
      "        [1603, 1668],\n",
      "        [2197, 2493],\n",
      "        [3802, 3830],\n",
      "        [1306, 1314],\n",
      "        [ 301,  324],\n",
      "        [5819, 5837]])\n",
      "tensor([[ 99.6056,  99.3198],\n",
      "        [ 99.6010,  99.3154],\n",
      "        [ 99.6010,  99.3154],\n",
      "        [ 99.6056,  99.3198],\n",
      "        [ 99.6010,  99.3152],\n",
      "        [-39.3468, -39.6628],\n",
      "        [ 99.6010,  99.3154],\n",
      "        [ 99.6010,  99.3154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 614,  649],\n",
      "        [  64,   98],\n",
      "        [1873, 1907],\n",
      "        [ 676,  703],\n",
      "        [ 488,  603],\n",
      "        [3171, 3186],\n",
      "        [1714, 1721],\n",
      "        [ 221,  232]])\n",
      "tensor([[100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488],\n",
      "        [100.5310, 100.2488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[5096, 5183],\n",
      "        [3544, 3676],\n",
      "        [   0,   16],\n",
      "        [2137, 2195],\n",
      "        [ 548,  551],\n",
      "        [1409, 1501],\n",
      "        [  58,   93],\n",
      "        [ 688,  791]])\n",
      "tensor([[101.4814, 101.2032],\n",
      "        [101.4858, 101.2074],\n",
      "        [101.4858, 101.2074],\n",
      "        [101.4858, 101.2074],\n",
      "        [101.4858, 101.2074],\n",
      "        [101.4858, 101.2074],\n",
      "        [101.4814, 101.2032],\n",
      "        [101.4858, 101.2074]], grad_fn=<AddmmBackward>)\n",
      "tensor([[  22,   32],\n",
      "        [1125, 1130],\n",
      "        [ 594,  604],\n",
      "        [1250, 1308],\n",
      "        [ 122,  130],\n",
      "        [ 439,  504],\n",
      "        [1765, 1777],\n",
      "        [ 260,  270]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-29f6d20e7dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-227-abedf0d9fa8c>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, lr, train_dl, val_dl, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss %.3f val loss %.3f and val accuracy %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-227-abedf0d9fa8c>\u001b[0m in \u001b[0;36mval_metric\u001b[0;34m(model, val_dl)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-220-9d163cd1631b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(model, 0.01, train_dl, test_dl, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
